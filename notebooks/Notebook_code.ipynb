{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0xSTAErf3L8o"
   },
   "source": [
    "<div style=\"display: flex; background-color: RGB(119, 150, 203);\">\n",
    "    <h1 style=\"margin: auto; padding: 30px 30px 30px 30px; color: RGB(255,255,255);\">\n",
    "        <center>\n",
    "            <b>Scoring : Projet Telecom</b><br/>\n",
    "            <br/>\n",
    "            Rime Boumezaoued, Romain Pénichon et Claire Gefflot<br/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dBd5lqhS3L8t"
   },
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b><u>Contexte du projet</b><br/>\n",
    "<br/>\n",
    "• Réalisation d’une étude<br/>\n",
    "• <b>Données :</b> Comportement clients dans le domaine de la téléphonie mobile<br/>\n",
    "• <b>Objectif :</b> Trouver le meilleur modèle de score permettant d’identifier au mieux les « churners »<br/>\n",
    "• <b>Évènement cible :</b> Le « churn » (attrition, départ client) est défini comme l’entrée en période d’invalidité dans les 2 mois<br/>\n",
    "• <b>Contexte :</b> 2 opérateurs mobiles (ope1 et ope2) + 1 fixe.<br/>\n",
    "• Vous êtes “ope1”<br/>\n",
    "• Mobile, prépayé, grand public<br/>\n",
    "• <b>3 périodes :</b> validité (validity), grâce (grace: pas d’appels sortants), invalidité (after-grace: ni entrant ni sortant)<br/>\n",
    "• <b>Types de recharges :</b> 25, 50, 100, 200 sesterces<br/>\n",
    "• <b>Variable cible :</b> AFTERGRACE_FLAG<br/>\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EWp043ws3L8u"
   },
   "source": [
    "<a class=\"anchor\" id=\"table_of_contents\"></a>\n",
    "## Sommaire\n",
    "\n",
    "* [Data pre-processing](#chapter1)\n",
    "    * [Import des packages et data](#section_1_1)\n",
    "    * [Data cleaning](#section_1_2)\n",
    "* [Exploration data analysis (EDA)](#chapter2)\n",
    "* [Feature engineering](#chapter3)\n",
    "    * [Création d'indicateur](#section_3_1)\n",
    "    * [Pré-sélection des variables (Chi 2 et Student)](#section_3_2)\n",
    "    * [Encoding et scaling (train et validation set)](#section_3_3)\n",
    "    * [Sélection des variables - Regression logistique (RFE)](#section_3_4)\n",
    "* [Modélisation](#chapter4)\n",
    "    * [Régression logistique](#section_4_1)\n",
    "    * [XGBoost](#section_4_2)\n",
    "    * [LightGBM](#section_4_3)\n",
    "* [Choix du modèle final : XGBoost](#chapter5)\n",
    "    * [Analyse des résultats](#section_5_1)\n",
    "    * [Identification des variables les plus importantes](#section_5_2)\n",
    "    * [Interprétation du modèle](#section_5_3)\n",
    "    * [Sérialisation du modèle et déploiement en situation réelle](#section_5_4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DhmLCt7c3L8v"
   },
   "source": [
    "<a class=\"anchor\" id=\"chapter1\"></a>\n",
    "<div style=\"display: flex; background-color: RGB(119, 150, 203);\">\n",
    "    <h1 style=\"margin: auto; padding: 30px 30px 30px 30px; color: RGB(255,255,255);\">\n",
    "            <b>Data pre-processing</b>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XB6ngrQO3L8v",
    "tags": []
   },
   "source": [
    "<a class=\"anchor\" id=\"section_1_1\"></a>\n",
    "<div style=\"border: 1px solid RGB(119, 150, 203);\" >\n",
    "    <h3 style=\"margin: auto; padding: 20px; color: RGB(119, 150, 203); \">Imports des packages et data</h3>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2S-RAEwh3L8w"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pandas.api.types import is_numeric_dtype, is_object_dtype\n",
    "import numpy as np\n",
    "import os\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "import scipy.stats as st\n",
    "from pathlib import Path\n",
    "import io\n",
    "from unidecode import unidecode\n",
    "from skimpy import skim\n",
    "import sys\n",
    "from statistics import mean\n",
    "import warnings\n",
    "import re\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from tqdm import tqdm\n",
    "from tqdm.notebook import tqdm_notebook\n",
    "\n",
    "import sklearn\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler, MaxAbsScaler, RobustScaler, QuantileTransformer, PowerTransformer, OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.feature_selection import RFE, RFECV\n",
    "from sklearn.linear_model import LogisticRegression, LogisticRegressionCV\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score, mean_squared_error, mean_absolute_error, r2_score, confusion_matrix, f1_score\n",
    "import category_encoders as ce\n",
    "from pre_processing import pre_processing\n",
    "\n",
    "\n",
    "from sklearn.exceptions import DataConversionWarning\n",
    "from xgboost import XGBClassifier\n",
    "#from lightgbm import LGBMClassifier\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "#from catboost import CatBoostClassifier, Pool\n",
    "#from catboost import cv\n",
    "import optuna\n",
    "import joblib\n",
    "\n",
    "import shap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 483
    },
    "id": "UWpqCx6-3L8z",
    "outputId": "bf0d489c-a618-4aac-e03f-85c05bb07915"
   },
   "outputs": [],
   "source": [
    "# Read the dataset :\n",
    "\n",
    "pd.set_option(\"display.min_rows\", 10)\n",
    "pd.set_option(\"display.max_column\", 1000)\n",
    "\n",
    "df = pd.read_csv('../DATA/base_projet_teleco.csv', index_col=False, sep=\";\") #../DATA/base_projet_teleco.csv or gs://scoring-data-m2tide/DATA/base_projet_teleco.csv\n",
    "df=df.iloc[:, 1:]\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nmOhkI6-3L8z"
   },
   "source": [
    "<a class=\"anchor\" id=\"section_1_2\"></a>\n",
    "<div style=\"border: 1px solid RGB(119, 150, 203);\" >\n",
    "    <h3 style=\"margin: auto; padding: 20px; color: RGB(119, 150, 203); \">Exploration des données</h3>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ISrhkfng3L80",
    "outputId": "285e37b7-5ef8-48f9-ebfb-71bc9f74268a"
   },
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KRSW4t6d3L81",
    "outputId": "2802cbcb-e787-4837-8f4c-5fb39d354a4a"
   },
   "outputs": [],
   "source": [
    "def df_analyse(df, columns, name_df):\n",
    "    \"\"\"\n",
    "    Initial analysis on the DataFrame.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    Args:\n",
    "        df (pandas.DataFrame): DataFrame to analyze.\n",
    "        columns (list): Dataframe keys in list format.\n",
    "        name_df (str): DataFrame name.\n",
    "\n",
    "    Returns:\n",
    "        None.\n",
    "        Print the initial analysis on the DataFrame.\n",
    "    \"\"\"\n",
    "\n",
    "    # Calculating the memory usage based on dataframe.info()\n",
    "    buf = io.StringIO()\n",
    "    df.info(buf=buf)\n",
    "    memory_usage = buf.getvalue().split('\\n')[-2]\n",
    "\n",
    "    if df.empty:\n",
    "        print(\"The\", name_df, \"dataset is empty. Please verify the file.\")\n",
    "    else:\n",
    "        # identifying empty columns\n",
    "        empty_cols = [col for col in df.columns if df[col].isna().all()]\n",
    "        #identifying full duplicates rows\n",
    "        df_rows_duplicates = df[df.duplicated()]\n",
    "\n",
    "        # Creating a dataset based on Type object and records by columns\n",
    "        type_cols = df.dtypes.apply(lambda x: x.name).to_dict()\n",
    "        df_resume = pd.DataFrame(list(type_cols.items()), columns = [\"Name\", \"Type\"])\n",
    "        df_resume[\"Records\"] = list(df.count())\n",
    "        df_resume[\"% of NaN\"] = list(round((df.isnull().sum(axis = 0))/len(df),5)*100)\n",
    "        df_resume[\"Unique\"] = list(df.nunique())\n",
    "\n",
    "\n",
    "        print(\"\\nInitial Analysis of\", name_df, \"dataset\")\n",
    "        print(\"--------------------------------------------------------------------------\")\n",
    "        print(\"- Dataset shape:                 \", df.shape[0], \"rows and\", df.shape[1], \"columns\")\n",
    "        print(\"- Total of NaN values:           \", df.isna().sum().sum())\n",
    "        #print(\"- Percentage of NaN:             \", round((df.isna().sum().sum() / prod(df.shape)) * 100, 2), \"%\")\n",
    "        print(\"- Total of full duplicates rows: \", df_rows_duplicates.shape[0])\n",
    "        print(\"- Total of empty rows:           \", df.shape[0] - df.dropna(axis=\"rows\", how=\"all\").shape[0]) if df.dropna(axis=\"rows\", how=\"all\").shape[0] < df.shape[0] else \\\n",
    "                    print(\"- Total of empty rows:            0\")\n",
    "        print(\"- Total of empty columns:        \", len(empty_cols))\n",
    "        print(\"  + The empty column is:         \", empty_cols) if len(empty_cols) == 1 else \\\n",
    "                    print(\"  + The empty column are:         \", empty_cols) if len(empty_cols) >= 1 else None\n",
    "\n",
    "        print(\"\\n- The key(s):\", columns, \"is not present multiple times in the dataframe.\\n  It CAN be used as a primary key.\") if df.size == df.drop_duplicates(columns).size else \\\n",
    "                    print(\"\\n- The key(s):\", columns, \"is present multiple times in the dataframe.\\n  It CANNOT be used as a primary key.\")\n",
    "\n",
    "        print(\"\\n- Type object and records by columns         (\",memory_usage,\")\")\n",
    "        print(\"--------------------------------------------------------------------------\")\n",
    "        print(df_resume.sort_values(\"Records\", ascending=False))\n",
    "\n",
    "\n",
    "\n",
    "# Analyse df\n",
    "df_analyse(df, [\"CONTRACT_KEY\"], \"df\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H5ws0LHf3L85",
    "tags": []
   },
   "source": [
    "<a class=\"anchor\" id=\"section_1_3\"></a>\n",
    "<div style=\"border: 1px solid RGB(119, 150, 203);\" >\n",
    "    <h3 style=\"margin: auto; padding: 20px; color: RGB(119, 150, 203); \">Data cleaning</h3>\n",
    "</div"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"border: 1px solid RGB(119, 150, 203);\" >\n",
    "    <h3 style=\"margin: auto; padding: 20px; color: black; \">Traitements basiques des données</h3>\n",
    "</div"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop duplicate : \n",
    "df.duplicated().value_counts()\n",
    "df.drop_duplicates(inplace=True, keep=\"first\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "m8bvCVaV3L85"
   },
   "outputs": [],
   "source": [
    "#drop useless col : \"CONTRACT_KEY\"\n",
    "df.drop([\"CONTRACT_KEY\"], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VQTyvGGw3L87"
   },
   "outputs": [],
   "source": [
    "#Handling data formatting: Data formatting involves making sure that the data is in a consistent format. It can be handled by converting data types, changing date formats, etc.\n",
    "#lowercase caracter :\n",
    "df = df.applymap(lambda s:s.lower() if type(s) == str else s) \n",
    "\n",
    "#drop white space :\n",
    "#df = df.applymap(lambda s:s.strip() if type(s) == str else s) \n",
    "\n",
    "#drop multiple(double, triple) space :\n",
    "#df = df.applymap(lambda s:s.replace(\"  \", \" \") if type(s) == str else s) \n",
    "\n",
    "#replace \" \" by \"_\" :\n",
    "#df = df.applymap(lambda s:s.replace(\" \", \"_\") if type(s) == str else s) \n",
    "\n",
    "#remove accent :\n",
    "#from unidecode import unidecode\n",
    "#df = df.applymap(lambda s: unidecode(s) if type(s) == str else s) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 419
    },
    "id": "VkPSlxG13L87",
    "outputId": "0413a024-9feb-4ecf-8f7c-4166506ab0c9"
   },
   "outputs": [],
   "source": [
    "# study the type and the number of unique value of each covariate\n",
    "df_nunique = pd.concat([df.nunique(), df.dtypes], axis=1).rename(columns={0: 'nunique', 1: 'dtypes'})\n",
    "df_nunique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop columns which have only 1 unique value :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XKalqxbg3L89"
   },
   "source": [
    "<div style=\"border: 1px solid RGB(119, 150, 203);\" >\n",
    "    <h3 style=\"margin: auto; padding: 20px; color: black; \">Traitements des valeurs anormales</h3>\n",
    "</div"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 483
    },
    "id": "0l2NEUzc3L89",
    "outputId": "370edf80-7c07-4402-ace8-bcf18a458c3c"
   },
   "outputs": [],
   "source": [
    "# Voir s'il y a des anomalies pour les var numeriques :\n",
    "# analyse if there is any anomaly before fillna : until PASS_AFTERGRACE_IND_M1\n",
    "df_describe = (df.describe()).T\n",
    "df_describe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Voir s'il y a des anomalies pour les var categorielles :\n",
    "# display(df[\"var_cat\"].unique())"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 306
    },
    "id": "aD9wETtQ3L8-",
    "outputId": "15f25a0a-dc28-4091-ecfa-ed2480d21281",
    "tags": []
   },
   "outputs": [],
   "source": [
    "#CUSTOMER_AGE : 18 to 100 year old\n",
    "#Est-il possible que les customer_age soit entre 0 et 99 ans ?\n",
    "display(df[\"CUSTOMER_AGE\"].unique())\n",
    "\n",
    "\n",
    "df[\"CUSTOMER_AGE\"] = df[\"CUSTOMER_AGE\"].apply(lambda x : np.nan if np.abs(x)<18 else np.abs(x))\n",
    "display(df[\"CUSTOMER_AGE\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "id": "Ucp_S4mE3L8-",
    "outputId": "be6c73f7-fec4-4bcf-dc7b-05b53bc74974"
   },
   "outputs": [],
   "source": [
    "#CUSTOMER_GENDER : Genre client\n",
    "display(df[\"CUSTOMER_GENDER\"].unique())\n",
    "\n",
    "df[\"CUSTOMER_GENDER\"] = df[\"CUSTOMER_GENDER\"].apply(lambda x : x.split(\"'\")[1])\n",
    "df[\"CUSTOMER_GENDER\"] = df[\"CUSTOMER_GENDER\"].apply(lambda x: np.nan if (x==\"not ent\" or x==\"unknown\") else x) #lambda x: \"unknown\" if (x==\"not ent\" or x==\"unknown\") else x\n",
    "\n",
    "display(df[\"CUSTOMER_GENDER\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tHUsstFS3L8_"
   },
   "outputs": [],
   "source": [
    "#CONTRACT_TENURE_DAYS : Ancienneté contrat en jours\n",
    "\"\"\"\n",
    "We know that :\n",
    "-Age min for contrat : 18\n",
    "If CONTRACT_TENURE_DAYS=365 = 365/365=1, then the minimum age = 18+1=19\n",
    "\n",
    "if current age - (CONTRACT_TENURE_DAYS/365) < 18\n",
    "then : replace by np.nan\n",
    "else : it's good\n",
    "\"\"\"\n",
    "\n",
    "df[\"age_first_contract\"] = df[\"CUSTOMER_AGE\"] - (df[\"CONTRACT_TENURE_DAYS\"]/365)\n",
    "df.loc[df['age_first_contract'] < 18, 'CONTRACT_TENURE_DAYS'] = np.nan\n",
    "df.drop([\"age_first_contract\"], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OH7yCrmi3L9A"
   },
   "outputs": [],
   "source": [
    "# 'NO_OF_RECHARGES_6M' :\n",
    "df.loc[(df['NO_OF_RECHARGES_6M']-df['FAILED_RECHARGE_6M']) < 0, 'NO_OF_RECHARGES_6M'] = np.nan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BxBoU9su8ZCZ"
   },
   "source": [
    "Aucune erreurs à signaler sur ces variables :\n",
    "AVERAGE_CHARGE_6M, FAILED_RECHARGE_6M, AVERAGE_RECHARGE_TIME_6M, BALANCE_M3, BALANCE_M2, BALANCE_M1, FIRST_RECHARGE_VALUE, LAST_RECHARGE_VALUE, TIME_TO_GRACE, TIME_TO_AFTERGRACE, RECENCY_OF_LAST_RECHARGE, TOTAL_RECHARGE_6M, ZERO_BALANCE_IND_M3, ZERO_BALANCE_IND_M2, ZERO_BALANCE_IND_M1, PASS_GRACE_IND_M3, PASS_GRACE_IND_M2, PASS_GRACE_IND_M1, PASS_AFTERGRACE_IND_M3, PASS_AFTERGRACE_IND_M2, PASS_AFTERGRACE_IND_M1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GXgc06-A8ZCZ"
   },
   "source": [
    "<div style=\"border: 1px solid RGB(119, 150, 203);\" >\n",
    "    <h3 style=\"margin: auto; padding: 20px; color: black; \">Transformation des variables</h3>\n",
    "</div"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "C88lVg8I3L9A"
   },
   "outputs": [],
   "source": [
    "#phones_data = pd.read_excel(\"marque_telephone.xlsx\")\n",
    "phones_data = pd.read_csv(\"../DATA/marque_telephone.csv\") #../DATA/marque_telephone.csv or gs://scoring-data-m2tide/DATA/marque_telephone.csv\n",
    "phones_data = phones_data.applymap(lambda x: x.lower() if isinstance(x, str) else x)\n",
    "\n",
    "duplicates = phones_data.duplicated(subset='model', keep=False)\n",
    "\n",
    "# Supprimer les doublons de l'index dans phones_data\n",
    "phones_data = phones_data.drop_duplicates(subset='model')\n",
    "\n",
    "# Créer une nouvelle colonne 'Marque' dans df\n",
    "df['marque'] = df['CURR_HANDSET_MODE'].map(phones_data.set_index('model')['marque_tel'])\n",
    "\n",
    "#drop \"CURR_HANDSET_MODE\":\n",
    "df.drop([\"CURR_HANDSET_MODE\"], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sG3roVgB3L9B",
    "outputId": "dc396ae9-5314-48f6-e2f1-c9acf802871f"
   },
   "outputs": [],
   "source": [
    "df['marque'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RnEy4Wvg3L9C"
   },
   "outputs": [],
   "source": [
    "# proportion de valeurs négatives pour les trois variables concernées\n",
    "col = [\"INC_OUT_PROP_DUR_MIN_M1\", \"INC_OUT_PROP_DUR_MIN_M2\", \"INC_OUT_PROP_DUR_MIN_M3\"]\n",
    "for elem in col :\n",
    "    df[elem] = np.where(df[elem] < 0, np.abs(df[elem]), df[elem])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ev-dD6cc3L9D",
    "outputId": "1c0ebfb7-26ae-4ac0-ae8d-01c6a6c108fc"
   },
   "outputs": [],
   "source": [
    "df.CONTRACT_TENURE_DAYS.sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DzPWaV-63L9E"
   },
   "source": [
    "<div style=\"border: 1px solid RGB(119, 150, 203);\" >\n",
    "    <h3 style=\"margin: auto; padding: 20px; color: black; \">Analyse des données après nettoyage</h3>\n",
    "</div"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 483
    },
    "id": "u-C57mMs3L9G",
    "outputId": "5e0d79a2-6b5e-413a-fed0-3a93a5a7a5ef"
   },
   "outputs": [],
   "source": [
    "df_describe = (df.describe()).T\n",
    "df_describe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "skim(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<div style=\"border: 1px solid RGB(119, 150, 203);\" >\n",
    "    <h3 style=\"margin: auto; padding: 20px; color: black; \">Split df</h3>\n",
    "</div"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FJnmvMjs3L9J"
   },
   "source": [
    "Afin d'éviter tout biais au sein de nos ensembles de données lors des imputations de valeurs manquantes, nous procédons immédiatement au split."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "En1HAku13L9K"
   },
   "source": [
    "### Split data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pbJ1EAR73L9L"
   },
   "outputs": [],
   "source": [
    "target = \"AFTERGRACE_FLAG\"\n",
    "df_train, df_val = train_test_split(df, test_size=0.2, stratify=df[target], random_state=14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#verify the distrib\n",
    "import seaborn as sns\n",
    "sns.displot(df_train[target], stats=\"percent\")\n",
    "sns.displot(df_val[target], stats=\"percent\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 483
    },
    "id": "drtXMI3m3L9N",
    "outputId": "593473bf-0ca3-4a83-aaec-67b156d74f32"
   },
   "outputs": [],
   "source": [
    "df_train.reset_index(drop = True, inplace=True)\n",
    "df_val.reset_index(drop = True, inplace=True)\n",
    "\n",
    "df_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Lt58V0tm3L9I"
   },
   "source": [
    "\n",
    "<div style=\"border: 1px solid RGB(119, 150, 203);\" >\n",
    "    <h3 style=\"margin: auto; padding: 20px; color: black; \">Imputation des valeurs manquantes</h3>\n",
    "</div"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RwlVizTF3L9O"
   },
   "source": [
    "### Traitement df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 483
    },
    "id": "oD9V8NWl3L9Q",
    "outputId": "497734d0-b5a0-414b-b232-af07f9a9f3b8"
   },
   "outputs": [],
   "source": [
    "#1/ fillna : (mean, median,...)\n",
    "\n",
    "#1.1/ Drop rows and col which are more 60-70% of NaN.\n",
    "#If there is 50%-60% or more NaN, drop the column.\n",
    "df_train_na_col = (pd.DataFrame(((df_train.isna().sum(axis=0))/len(df_train))*100)).rename(columns={0: 'Sum_NaN_%'})\n",
    "\n",
    "#drop col :\n",
    "df_train.drop(columns=list((df_train_na_col[df_train_na_col[\"Sum_NaN_%\"]>50]).index), inplace=True)\n",
    "\n",
    "#Count the number of NaN in rows :\n",
    "#If there is 60-70% or more NaN, drop the row.\n",
    "df_train_na_row = (pd.DataFrame(((df_train.isna().sum(axis=1))/len(df_train.columns))*100)).rename(columns={0: 'Sum_NaN_%'})\n",
    "\n",
    "#drop row :\n",
    "df_train.drop(index=list((df_train_na_row[df_train_na_row[\"Sum_NaN_%\"]>60]).index), inplace=True)\n",
    "\n",
    "#reset_index :\n",
    "df_train.reset_index(drop = True, inplace=True)\n",
    "\n",
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Lzzvs8WC3L9R"
   },
   "outputs": [],
   "source": [
    "#1.2/ dectect col which have NaN\n",
    "df_train_na = (pd.DataFrame(df_train.isna().sum())).rename(columns={0: 'Sum_NaN'})\n",
    "df_train_na_egal_0 = df_train_na[df_train_na['Sum_NaN']==0]\n",
    "df_train_na_diff_0 = df_train_na[df_train_na['Sum_NaN']!=0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "5sn0r8ev3L9S",
    "outputId": "c68cab2c-2a7a-4e23-ba5d-8249f556a414"
   },
   "outputs": [],
   "source": [
    "df_train_na_diff_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uHfTp83C3L9T"
   },
   "outputs": [],
   "source": [
    "#1.3/Build groupby df for fillna :\n",
    "#select best col for groupby fillna :\n",
    "target = \"AFTERGRACE_FLAG\"\n",
    "corr_matrix = df_train[list(df_train_na_egal_0.index)].corr().abs().loc[target].drop([target], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 607
    },
    "id": "JbQoOSXH3L9W",
    "outputId": "dda84158-7671-42ca-fc2e-c7f214071125"
   },
   "outputs": [],
   "source": [
    "corr_matrix = pd.concat([corr_matrix, df_train[list(corr_matrix.index)].nunique()], axis=1).rename(columns={0: 'nunique'})\n",
    "corr_matrix.sort_values(by=[\"AFTERGRACE_FLAG\", \"nunique\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TxENTl_MCTel"
   },
   "source": [
    "Les variables (sans NaN) les plus corrélées à la target avec un nombre réduit de modalités sont :\n",
    "- PASS_GRACE_IND_M1\n",
    "- PASS_GRACE_IND_M2\n",
    "- PASS_GRACE_IND_M3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BCfu8zIf3L9Z"
   },
   "outputs": [],
   "source": [
    "df_train_grouby_3var = df_train.groupby([\"PASS_GRACE_IND_M1\", \"PASS_GRACE_IND_M2\", \"PASS_GRACE_IND_M3\"])\n",
    "df_train_grouby_2var = df_train.groupby([\"PASS_GRACE_IND_M1\", \"PASS_GRACE_IND_M2\"])\n",
    "df_train_grouby_1var = df_train.groupby([\"PASS_GRACE_IND_M1\"])"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Imputation :\n",
    "- replace NaN num var by median \n",
    "\n",
    "- replace \"marque\" by \"unknown\"\n",
    "- replace the rest of NaN cat var by mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# useless here :\n",
    "\"\"\"\n",
    "list_median_mode_imputation = []\n",
    "list_cat_particular_imputation = [\"marque\"]\n",
    "list_cont_particular_imputation = [i for i in list(df_train.columns) if i not in list_median_mode_imputation + list_cat_particular_imputation + [target] + [\"PASS_GRACE_IND_M1\", \"PASS_GRACE_IND_M2\", \"PASS_GRACE_IND_M3\"]]\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ClvXRpEk3L9a",
    "outputId": "71b78ab4-b7fb-48ee-85b9-75968bb8d4d6"
   },
   "outputs": [],
   "source": [
    "#1.4/fillna on dataset : \n",
    "\n",
    "# numerical col :\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "#fillna with particular value :\n",
    "#df_train[\"num_var\"] = df_train[\"num_var\"].fillna(\"numerical_value\")\n",
    "#df_train[list_cont_particular_imputation] = df_train[list_cont_particular_imputation].fillna(common value, example = 0)\n",
    "\n",
    "\n",
    "#fillna with median :\n",
    "target = \"AFTERGRACE_FLAG\"\n",
    "for i in (df_train_na_diff_0.index) : # or replace (df_train_na_diff_0.index) by list_median_mode_imputation\n",
    "    if is_numeric_dtype(df_train[i]) and i != target :\n",
    "        df_train[i] = df_train_grouby_3var[i].fillna(df_train[i].median()) #df_train.groupby([\"PASS_GRACE_IND_M1\", \"PASS_GRACE_IND_M2\", \"PASS_AFTERGRACE_IND_M2\"])[i].fillna(df_train[i].median())\n",
    "        df_train[i] = df_train_grouby_2var[i].fillna(df_train[i].median())\n",
    "        df_train[i] = df_train_grouby_1var[i].fillna(df_train[i].median())\n",
    "\n",
    "        df_train[i] = df_train[i].fillna(df_train[i].median())\n",
    "\n",
    "print(df_train.isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#categorical col :\n",
    "\n",
    "#fillna with particular value :\n",
    "#df_train[\"var\"] = df_train[\"var\"].fillna(\"string_value\")\n",
    "#df_train[list_cat_particular_imputation].fillna(\"cat_value\", inplace=True)\n",
    "df_train['marque'].fillna(\"unknown\", inplace=True)\n",
    "\n",
    "\n",
    "#fillna with mode :\n",
    "target = \"AFTERGRACE_FLAG\"\n",
    "for i in (df_train_na_diff_0.index) :  # or replace (df_train_na_diff_0.index) by list_median_mode_imputation\n",
    "    if is_object_dtype(df_train[i]) and i != target :\n",
    "        df_train[i] = df_train_grouby_3var[i].fillna(df_train[i].mode()[0]) ##df_train.groupby([\"PASS_GRACE_IND_M1\", \"PASS_GRACE_IND_M2\", \"PASS_AFTERGRACE_IND_M2\"])[i].fillna(df_train[i].mode())\n",
    "        df_train[i] = df_train_grouby_2var[i].fillna(df_train[i].mode()[0])\n",
    "        df_train[i] = df_train_grouby_1var[i].fillna(df_train[i].mode()[0])\n",
    "        \n",
    "        df_train[i] = df_train[i].fillna(df_train[i].mode()[0])\n",
    "\n",
    "print(df_train.isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sYIomgEp3L9b"
   },
   "outputs": [],
   "source": [
    "(pd.DataFrame(((df_train.isna().sum(axis=0))/len(df_train))*100)).rename(columns={0: 'Sum_NaN_%'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "o3vlMEsq3L9c"
   },
   "source": [
    "### Traitement df_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1.1/ Drop rows and col which are more 60-70% of NaN.\n",
    "#If there is 50%-60% or more NaN, drop the column.\n",
    "#drop col :\n",
    "df_val.drop(columns=list((df_train_na_col[df_train_na_col[\"Sum_NaN_%\"]>50]).index), inplace=True)\n",
    "\n",
    "#Count the number of NaN in rows :\n",
    "#If there is 60-70% or more NaN, drop the row.\n",
    "#useless for row of df_val "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EO2bXi6p3L9c",
    "outputId": "96fc78b4-6b55-4c08-aeae-eb86ffc6a962"
   },
   "outputs": [],
   "source": [
    "#1.1/ verify if columns (which we use for groupby) have NaN or not :\n",
    "groupby_columns = [\"PASS_GRACE_IND_M1\", \"PASS_GRACE_IND_M2\", \"PASS_GRACE_IND_M3\"]\n",
    "df_val[groupby_columns].isna().sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5X25rdrc3L9d"
   },
   "outputs": [],
   "source": [
    "# if there is NaN, fillna them by the median/mean or mode from df_train\n",
    "\n",
    "#numerical col :\n",
    "for i in groupby_columns :\n",
    "    df_val[i] = df_val[i].fillna(df_train[i].median())\n",
    "\n",
    "#cat col :\n",
    "for i in groupby_columns :\n",
    "    df_val[i] = df_val[i].fillna(df_train[i].mode())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4kkfi8FD3L9d"
   },
   "outputs": [],
   "source": [
    "#1.2/dectect col which have NaN\n",
    "df_val_na = (pd.DataFrame(df_val.isna().sum())).rename(columns={0: 'Sum_NaN'})\n",
    "df_val_na_egal_0 = df_val_na[df_val_na['Sum_NaN']==0]\n",
    "df_val_na_diff_0 = df_val_na[df_val_na['Sum_NaN']!=0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 419
    },
    "id": "iTjaBrGK3L9e",
    "outputId": "0a752836-3ae8-4d71-b94c-4adc91608978"
   },
   "outputs": [],
   "source": [
    "#1.2/fillna on dataset :\n",
    "\n",
    "#numerical col :\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "#fillna with particular value :\n",
    "#df_val[\"var\"] = df_val[\"var\"].fillna(\"numerical_value\")\n",
    "#df_val[list_cont_particular_imputation] = df_val[list_cont_particular_imputation].fillna(0)\n",
    "\n",
    "\n",
    "#fillna with median :\n",
    "target = \"AFTERGRACE_FLAG\"\n",
    "\n",
    "def imputate_missing_3val(df) :\n",
    "    if pd.isna(df[i]) :\n",
    "        return (df_train_grouby_3var.get_group((\"PASS_GRACE_IND_M1\"==df[\"PASS_GRACE_IND_M1\"], \"PASS_GRACE_IND_M2\"==df[\"PASS_GRACE_IND_M2\"], \"PASS_GRACE_IND_M3\"==df[\"PASS_GRACE_IND_M3\"]))[[elem for elem in df_val.columns if is_numeric_dtype(df_val[elem])]].agg(\"median\"))[i]\n",
    "    else :\n",
    "        return df[i]\n",
    "\n",
    "    \n",
    "def imputate_missing_2val(df) :\n",
    "    if pd.isna(df[i]) :\n",
    "        return (df_train_grouby_2var.get_group((\"PASS_GRACE_IND_M1\"==df[\"PASS_GRACE_IND_M1\"], \"PASS_GRACE_IND_M2\"==df[\"PASS_GRACE_IND_M2\"]))[[elem for elem in df_val.columns if is_numeric_dtype(df_val[elem])]].agg(\"median\"))[i]\n",
    "    else :\n",
    "        return df[i]\n",
    "\n",
    "def imputate_missing_1val(df) :\n",
    "    if pd.isna(df[i]) :\n",
    "        return (df_train_grouby_1var.get_group((\"PASS_GRACE_IND_M1\"==df[\"PASS_GRACE_IND_M1\"]))[[elem for elem in df_val.columns if is_numeric_dtype(df_val[elem])]].agg(\"median\"))[i]\n",
    "    else :\n",
    "        return df[i]\n",
    "\n",
    "for i in (df_val_na_diff_0.index) : #or list_median_mode_imputation\n",
    "    if is_numeric_dtype(df_val[i]) and i != target :\n",
    "        df_val[i] = df_val.apply(imputate_missing_3val, axis=1)\n",
    "        df_val[i] = df_val.apply(imputate_missing_2val, axis=1)\n",
    "        df_val[i] = df_val.apply(imputate_missing_1val, axis=1)\n",
    "        df_val[i] = df_val[i].fillna(df_train[i].median())\n",
    "\n",
    "\n",
    "pd.DataFrame(df_val.isna().sum()).sort_values(by=[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 419
    },
    "id": "WQCMCAgF8ZCf",
    "outputId": "06b7397c-be1b-4486-9a48-61fbff7a20ea"
   },
   "outputs": [],
   "source": [
    "#caterical col :\n",
    "from pandas.api.types import is_numeric_dtype, is_object_dtype\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "#fillna with particular value :\n",
    "#df_val[\"var\"] = df_val[\"var\"].fillna(\"categorical_value\")\n",
    "df_val['marque'].fillna(\"unknown\", inplace=True)\n",
    "\n",
    "\n",
    "#fillna with mode :\n",
    "target = \"AFTERGRACE_FLAG\"\n",
    "\n",
    "def imputate_missing_3val(df) :\n",
    "    if pd.isna(df[i]) :\n",
    "        return (df_train_grouby_3var.get_group((\"PASS_GRACE_IND_M1\"==df[\"PASS_GRACE_IND_M1\"], \"PASS_GRACE_IND_M2\"==df[\"PASS_GRACE_IND_M2\"],\n",
    "                                                \"PASS_GRACE_IND_M3\"==df[\"PASS_GRACE_IND_M3\"]))[[elem for elem in df_val.columns if is_object_dtype(df_val[elem])]].agg(\"mode\"))[i][0]\n",
    "    else :\n",
    "        return df[i]\n",
    "    \n",
    "def imputate_missing_2val(df) :\n",
    "    if pd.isna(df[i]) :\n",
    "        return (df_train_grouby_2var.get_group((\"PASS_GRACE_IND_M1\"==df[\"PASS_GRACE_IND_M1\"],\n",
    "                                                \"PASS_GRACE_IND_M2\"==df[\"PASS_GRACE_IND_M2\"]))[[elem for elem in df_val.columns if is_object_dtype(df_val[elem])]].agg(\"mode\"))[i][0]\n",
    "    else :\n",
    "        return df[i]\n",
    "\n",
    "def imputate_missing_1val(df) :\n",
    "    if pd.isna(df[i]) :\n",
    "        return (df_train_grouby_1var.get_group((\"PASS_GRACE_IND_M1\"==df[\"PASS_GRACE_IND_M1\"]))[[elem for elem in df_val.columns if is_object_dtype(df_val[elem])]].agg(\"mode\"))[i][0]\n",
    "    else :\n",
    "        return df[i]\n",
    "\n",
    "\n",
    "for i in (df_val_na_diff_0.index) : #or list_median_mode_imputation\n",
    "    if is_object_dtype(df_val[i]) and i != target :\n",
    "        if df_val[i].isnull().values.any() :\n",
    "            df_val[i] = df_val.apply(imputate_missing_3val, axis=1)\n",
    "            df_val[i] = df_val.apply(imputate_missing_2val, axis=1)\n",
    "            df_val[i] = df_val.apply(imputate_missing_1val, axis=1)\n",
    "            df_val[i] = df_val[i].fillna(df_train[i].mode())\n",
    "\n",
    "\n",
    "pd.DataFrame(df_val.isna().sum()).sort_values(by=[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 483
    },
    "id": "cuEEg3VO3L9f",
    "outputId": "dd103047-226a-45d5-ce5e-c5abeaea74e0"
   },
   "outputs": [],
   "source": [
    "df_val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Traitement df_test\n",
    "Ici on utilise que le val, donc pas de traitement sur df_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"chapter2\"></a>\n",
    "<div style=\"display: flex; background-color: RGB(119, 150, 203);\">\n",
    "    <h1 style=\"margin: auto; padding: 30px 30px 30px 30px; color: RGB(255,255,255);\">\n",
    "            <b>Exploration data analysis (EDA) on df_train</b>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "skim(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Création d'un DataFrame pour stocker les types de données des colonnes dans df\n",
    "info_types = pd.DataFrame(df_train.dtypes, columns=['type'])\n",
    "info_types.sort_values('type')  # Tri par la colonne 'type'\n",
    "\n",
    "# Définition de la variable cible\n",
    "target = \"AFTERGRACE_FLAG\"\n",
    "\n",
    "# Sélection des colonnes numériques à l'exclusion de la variable cible\n",
    "var_num = df_train.select_dtypes(include=np.number).columns.tolist()\n",
    "#var_num.remove(\"AFTERGRACE_FLAG\")\n",
    "\n",
    "# Sélection des colonnes catégorielles à l'exclusion de la variable CURR_HANDSET_MODE\n",
    "var_cat = df_train.select_dtypes(include=object).columns.tolist()\n",
    "#var_cat.remove(\"CURR_HANDSET_MODE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Définition d'une fonction pour tracer la distribution d'une variable catégorielle par rapport à la variable cible\n",
    "def distrib_for_cat_by_target(var_cat: list, dataframe, target: str):\n",
    "    temp = dataframe.copy()\n",
    "    temp['Frequency'] = 0\n",
    "    counts = temp.groupby([target, var_cat]).count()\n",
    "    freq_per_group = counts.div(counts.groupby(target).transform('sum')).reset_index()\n",
    "    g = sns.catplot(x=target, y=\"Frequency\", hue=var_cat, data=freq_per_group, kind=\"bar\",\n",
    "                  height=8, aspect=2, legend=False)\n",
    "    ax = g.ax\n",
    "    for p in ax.patches:\n",
    "        ax.annotate(f\"{p.get_height()*100:.2f}%\", (p.get_x() + p.get_width() / 2., p.get_height()),\n",
    "                    ha='center', va='center', fontsize=14, color='black', xytext=(0, 20),\n",
    "                    textcoords='offset points')\n",
    "    plt.title(\"Distribution de '\" + var_cat + \"' par 'Cible'\", fontsize=22)\n",
    "    plt.legend(fontsize=14)\n",
    "    plt.xlabel(target, fontsize=18)\n",
    "    plt.ylabel('Fréquence', fontsize=18)\n",
    "    plt.show()\n",
    "\n",
    "# Tracer la distribution des variables catégorielles par rapport à la variable\n",
    "for i in var_cat:\n",
    "    distrib_for_cat_by_target(i,df_train,target)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Définition d'une fonction pour tracer la distribution d'une variable numérique par rapport à la variable cible\n",
    "def distrib_for_num_by_target(var_num: list, dataframe, target: str):\n",
    "    \"\"\"\n",
    "    Fonction de distribution d'une variable explicative selon la variable cible (x|y)\n",
    "    var_num : variable explicative à étudier\n",
    "    dataframe\n",
    "    target : variable cible\n",
    "    \"\"\"\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, sharey=True, figsize=(14, 7))\n",
    "    sns.distplot(dataframe[dataframe[target] == 0][var_num], ax=ax1)\n",
    "    sns.distplot(dataframe[dataframe[target] == 1][var_num], ax=ax2)\n",
    "    ax1.set_title(\"Distribution de la variable \" + var_num + f\" \\n pour '{target}' = 0\")\n",
    "    ax2.set_title(\"Distribution de la variable \" + var_num + f\" \\n pour '{target}' = 1\")\n",
    "    plt.show()\n",
    "\n",
    "# Tracer la distribution des variables numériques par rapport à la variable cible\n",
    "\n",
    "for i in var_num:\n",
    "    distrib_for_num_by_target(i, df_train, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Matrice de corrélation\n",
    "correlation_matrix = df_train[[elem for elem in df_train.columns if is_numeric_dtype(df_train[elem])]].corr()\n",
    "\n",
    "# Sélection des variables les plus corrélées à AFTERGRACE_FLAG avec une corrélation supérieure à 0.15\n",
    "threshold = 0.15\n",
    "target_correlations = correlation_matrix['AFTERGRACE_FLAG'][(correlation_matrix['AFTERGRACE_FLAG'] > threshold) | (correlation_matrix['AFTERGRACE_FLAG'] < -threshold)]\n",
    "\n",
    "# Filtrage du DataFrame original pour les variables sélectionnées\n",
    "filtered_df = df_train[target_correlations.index]\n",
    "\n",
    "# Création d'une nouvelle matrice de corrélation avec les variables sélectionnées\n",
    "filtered_correlation_matrix = filtered_df.corr()\n",
    "\n",
    "# Création de la heatmap de la matrice de corrélation filtrée\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(filtered_correlation_matrix, annot=True, cmap='coolwarm', center=0, fmt=\".2f\", annot_kws={\"ha\": 'center'})\n",
    "plt.title(\"Matrice de corrélation avec variables corrélées à AFTERGRACE_FLAG (corrélation > 0.15)\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AdnRhX5j3L9g"
   },
   "source": [
    "<a class=\"anchor\" id=\"chapter3\"></a>\n",
    "<div style=\"display: flex; background-color: RGB(119, 150, 203);\">\n",
    "    <h1 style=\"margin: auto; padding: 30px 30px 30px 30px; color: RGB(255,255,255);\">\n",
    "            <b>Feature engineering</b>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0FTiQzQI3L9g",
    "tags": []
   },
   "source": [
    "<a class=\"anchor\" id=\"section_3_1\"></a>\n",
    "<div style=\"border: 1px solid RGB(119, 150, 203);\" >\n",
    "    <h3 style=\"margin: auto; padding: 20px; color: RGB(119, 150, 203); \">Création d'indicateur</h3>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Zd7GALAt3L9h"
   },
   "source": [
    "Pour les données d'entraînement :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4FH7KDrO3L9h"
   },
   "outputs": [],
   "source": [
    "# les données sont figées à fin M1 (août), M2 = juillet etc jusqu'à M6 = mars\n",
    "\n",
    "# création de 4 variables (comme on cherche les churners dans les 2 mois)\n",
    "\n",
    "df_train[\"FLAG_RECHARGE_M1\"] = df_train[\"RECENCY_OF_LAST_RECHARGE\"].apply(lambda x : 1 if 0 <= x <= 31 else 0)\n",
    "\n",
    "df_train[\"FLAG_RECHARGE_M2\"] = df_train[\"RECENCY_OF_LAST_RECHARGE\"].apply(lambda x : 1 if 32 <= x <= 62 else 0)\n",
    "\n",
    "df_train[\"FLAG_RECHARGE_M3\"] = df_train[\"RECENCY_OF_LAST_RECHARGE\"].apply(lambda x : 1 if 63 <= x <= 92 else 0)\n",
    "\n",
    "df_train[\"FLAG_RECHARGE_PLUS_M3\"] = df_train[\"RECENCY_OF_LAST_RECHARGE\"].apply(lambda x : 1 if x >= 93 else 0) #plus loin que M3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "e8-rIbhg3L9h"
   },
   "outputs": [],
   "source": [
    "# approche via les balances : si balance M2 > M1 et balance M3 > M2 alors il a eu plusieurs recharges sur les 3 mois\n",
    "# marche que si balance = reste des recharges\n",
    "\n",
    "for index, row in df_train.iterrows():\n",
    "    if row[\"BALANCE_M2\"] > row[\"BALANCE_M1\"] and row[\"BALANCE_M3\"] > row[\"BALANCE_M2\"]:\n",
    "        df_train.at[index, \"AVERAGE_MULTIPLE_RECHARGE_M1_M2_M3\"] = 1\n",
    "\n",
    "    else :\n",
    "        df_train.at[index, \"AVERAGE_MULTIPLE_RECHARGE_M1_M2_M3\"] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9yS0-0PV3L9h"
   },
   "outputs": [],
   "source": [
    "# si quelque chose entre 1 sinon 0\n",
    "\n",
    "for index, row in df_train.iterrows() :\n",
    "    if row[\"INC_DURATION_MINS_M1\"] + row[\"INC_PROP_SMS_CALLS_M1\"] == 0 :\n",
    "        df_train.at[index, \"FLAG_IN_M1\"] = 0\n",
    "\n",
    "    else :\n",
    "        df_train.at[index, \"FLAG_IN_M1\"] = 1\n",
    "\n",
    "    if row[\"INC_DURATION_MINS_M2\"] + row[\"INC_PROP_SMS_CALLS_M2\"] == 0 :\n",
    "        df_train.at[index, \"FLAG_IN_M2\"] = 0\n",
    "\n",
    "    else :\n",
    "        df_train.at[index, \"FLAG_IN_M2\"] = 1\n",
    "\n",
    "    if row[\"INC_DURATION_MINS_M3\"] + row[\"INC_PROP_SMS_CALLS_M3\"] == 0 :\n",
    "        df_train.at[index, \"FLAG_IN_M3\"] = 0\n",
    "\n",
    "    else :\n",
    "        df_train.at[index, \"FLAG_IN_M3\"] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "e1ETdGcL3L9h"
   },
   "outputs": [],
   "source": [
    "# si quelque chose sort 1 sinon 0\n",
    "\n",
    "for index, row in df_train.iterrows() :\n",
    "    if row[\"OUT_DURATION_MINS_M1\"] + row[\"OUT_SMS_NO_M1\"] + row[\"OUT_INT_DURATION_MINS_M1\"] + row[\"OUT_888_DURATION_MINS_M1\"] + row[\"OUT_VMACC_NO_CALLS_M1\"] == 0:\n",
    "        df_train.at[index, \"FLAG_OUT_M1\"] = 0\n",
    "\n",
    "    else :\n",
    "        df_train.at[index, \"FLAG_OUT_M1\"] = 1\n",
    "\n",
    "    if row[\"OUT_DURATION_MINS_M2\"] + row[\"OUT_SMS_NO_M2\"] + row[\"OUT_INT_DURATION_MINS_M2\"] == 0 + row[\"OUT_888_DURATION_MINS_M2\"] + row[\"OUT_VMACC_NO_CALLS_M2\"] == 0 :\n",
    "        df_train.at[index, \"FLAG_OUT_M2\"] = 0\n",
    "\n",
    "    else :\n",
    "        df_train.at[index, \"FLAG_OUT_M2\"] = 1\n",
    "\n",
    "    if row[\"OUT_DURATION_MINS_M3\"] + row[\"OUT_SMS_NO_M3\"] + row[\"OUT_INT_DURATION_MINS_M3\"] + row[\"OUT_888_DURATION_MINS_M3\"] + row[\"OUT_VMACC_NO_CALLS_M3\"] == 0 :\n",
    "        df_train.at[index, \"FLAG_OUT_M3\"] = 0\n",
    "\n",
    "    else :\n",
    "\n",
    "        df_train.at[index, \"FLAG_OUT_M3\"] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dXFUdfFx3L9i"
   },
   "outputs": [],
   "source": [
    "# type de contrat : ancien ou nouveau (règle : si supérieur à 2 ans vieux sinon nouveau)\n",
    "\n",
    "\n",
    "for index, row in df_train.iterrows() :\n",
    "    if row[\"CONTRACT_TENURE_DAYS\"] > 730 :\n",
    "        df_train.at[index, \"OLD_CONTRACT\"] = 1\n",
    "\n",
    "    else :\n",
    "        df_train.at[index,\"OLD_CONTRACT\"] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r3LZnAoW3L9i"
   },
   "source": [
    "Pour les données de test/validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OnfenIXI3L9i"
   },
   "outputs": [],
   "source": [
    "# les données sont figées à fin M1 (août), M2 = juillet etc jusqu'à M6 = mars\n",
    "\n",
    "# création de 4 variables (comme on cherche les churners dans les 2 mois)\n",
    "\n",
    "df_val[\"FLAG_RECHARGE_M1\"] = df_val[\"RECENCY_OF_LAST_RECHARGE\"].apply(lambda x : 1 if 0 <= x <= 31 else 0)\n",
    "\n",
    "df_val[\"FLAG_RECHARGE_M2\"] = df_val[\"RECENCY_OF_LAST_RECHARGE\"].apply(lambda x : 1 if 32 <= x <= 62 else 0)\n",
    "\n",
    "df_val[\"FLAG_RECHARGE_M3\"] = df_val[\"RECENCY_OF_LAST_RECHARGE\"].apply(lambda x : 1 if 63 <= x <= 92 else 0)\n",
    "\n",
    "df_val[\"FLAG_RECHARGE_PLUS_M3\"] = df_val[\"RECENCY_OF_LAST_RECHARGE\"].apply(lambda x : 1 if x >= 93 else 0) #plus loin que M3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ILdpeUXZ3L9i"
   },
   "outputs": [],
   "source": [
    "# approche via les balances : si balance M1 > M2 ou balance M2 > M3 ou balance M1 > M3 alors il a eu plusieurs recharges sur les 3 mois\n",
    "# marche que si balance = reste des recharges\n",
    "\n",
    "for index, row in df_val.iterrows():\n",
    "    if row[\"BALANCE_M2\"] > row[\"BALANCE_M1\"] and row[\"BALANCE_M3\"] > row[\"BALANCE_M2\"]:\n",
    "        df_val.at[index, \"AVERAGE_MULTIPLE_RECHARGE_M1_M2_M3\"] = 1\n",
    "\n",
    "    else :\n",
    "        df_val.at[index, \"AVERAGE_MULTIPLE_RECHARGE_M1_M2_M3\"] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TvtnBPlo3L9j"
   },
   "outputs": [],
   "source": [
    "# si quelque chose entre 1 sinon 0\n",
    "\n",
    "for index, row in df_val.iterrows() :\n",
    "    if row[\"INC_DURATION_MINS_M1\"] + row[\"INC_PROP_SMS_CALLS_M1\"] == 0 :\n",
    "        df_val.at[index, \"FLAG_IN_M1\"] = 0\n",
    "\n",
    "    else :\n",
    "        df_val.at[index, \"FLAG_IN_M1\"] = 1\n",
    "\n",
    "    if row[\"INC_DURATION_MINS_M2\"] + row[\"INC_PROP_SMS_CALLS_M2\"] == 0 :\n",
    "        df_val.at[index, \"FLAG_IN_M2\"] = 0\n",
    "\n",
    "    else :\n",
    "        df_val.at[index, \"FLAG_IN_M2\"] = 1\n",
    "\n",
    "    if row[\"INC_DURATION_MINS_M3\"] + row[\"INC_PROP_SMS_CALLS_M3\"] == 0 :\n",
    "        df_val.at[index, \"FLAG_IN_M3\"] = 0\n",
    "\n",
    "    else :\n",
    "        df_val.at[index, \"FLAG_IN_M3\"] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qE2OYHvx3L9j"
   },
   "outputs": [],
   "source": [
    "# si quelque chose sort 1 sinon 0\n",
    "\n",
    "for index, row in df_val.iterrows() :\n",
    "    if row[\"OUT_DURATION_MINS_M1\"] + row[\"OUT_SMS_NO_M1\"] + row[\"OUT_INT_DURATION_MINS_M1\"] + row[\"OUT_888_DURATION_MINS_M1\"] + row[\"OUT_VMACC_NO_CALLS_M1\"] == 0:\n",
    "        df_val.at[index, \"FLAG_OUT_M1\"] = 0\n",
    "\n",
    "    else :\n",
    "        df_val.at[index, \"FLAG_OUT_M1\"] = 1\n",
    "\n",
    "    if row[\"OUT_DURATION_MINS_M2\"] + row[\"OUT_SMS_NO_M2\"] + row[\"OUT_INT_DURATION_MINS_M2\"] + row[\"OUT_888_DURATION_MINS_M2\"] + row[\"OUT_VMACC_NO_CALLS_M2\"] == 0 :\n",
    "        df_val.at[index, \"FLAG_OUT_M2\"] = 0\n",
    "\n",
    "    else :\n",
    "        df_val.at[index, \"FLAG_OUT_M2\"] = 1\n",
    "\n",
    "    if row[\"OUT_DURATION_MINS_M3\"] + row[\"OUT_SMS_NO_M3\"] + row[\"OUT_INT_DURATION_MINS_M3\"] + row[\"OUT_888_DURATION_MINS_M3\"] + row[\"OUT_VMACC_NO_CALLS_M3\"] == 0 :\n",
    "        df_val.at[index, \"FLAG_OUT_M3\"] = 0\n",
    "\n",
    "    else :\n",
    "\n",
    "        df_val.at[index, \"FLAG_OUT_M3\"] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XVTYy-En3L9k"
   },
   "outputs": [],
   "source": [
    "# type de contrat : ancien ou nouveau (règle : si supérieur à 2 ans vieux sinon nouveau)\n",
    "\n",
    "for index, row in df_val.iterrows() :\n",
    "    if row[\"CONTRACT_TENURE_DAYS\"] > 730 :\n",
    "        df_val.at[index, \"OLD_CONTRACT\"] = 1\n",
    "\n",
    "    else :\n",
    "        df_val.at[index, \"OLD_CONTRACT\"] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O6ZbTDio3L9k"
   },
   "source": [
    "<a class=\"anchor\" id=\"section_3_2\"></a>\n",
    "<div style=\"border: 1px solid RGB(119, 150, 203);\" >\n",
    "    <h3 style=\"margin: auto; padding: 20px; color: RGB(119, 150, 203); \">Pré-sélection des variables (filter methods)</h3>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YqyNs-QK3L9k"
   },
   "outputs": [],
   "source": [
    "# Variables catégortielles test du Chi 2:\n",
    "info_types = pd.DataFrame(df_train.dtypes)\n",
    "list_var_cat = info_types[info_types[0]==\"object\"].index.tolist()\n",
    "list_col_to_drop = []\n",
    "\n",
    "target = \"AFTERGRACE_FLAG\"\n",
    "for v in list_var_cat:\n",
    "    if v!=target:\n",
    "        cont = df_train[[v, target]].pivot_table(index=v, columns=target, aggfunc=len).fillna(0).copy().astype(int) # Création de la table de contingence\n",
    "        st_chi2, st_p, st_dof, st_exp = st.chi2_contingency(cont)\n",
    "\n",
    "        #col to drop :\n",
    "        if st_p >= 0.05 :\n",
    "            list_col_to_drop.append(v)\n",
    "\n",
    "        #print(v + \": p-value test chi 2 = \" + str(st_p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JkMJHOae3L9l"
   },
   "outputs": [],
   "source": [
    "info_df_num = df_train.describe()\n",
    "\n",
    "for v in info_df_num.columns.tolist():\n",
    "    if v!= target:\n",
    "        a=list(df_train[df_train[target]==0][v])\n",
    "        b=list(df_train[df_train[target]==1][v])\n",
    "        st_test, st_p = st.ttest_ind(a, b, axis=0, equal_var=False, nan_policy='omit')\n",
    "\n",
    "        #col to drop :\n",
    "        if st_p >= 0.05 :\n",
    "            list_col_to_drop.append(v)\n",
    "\n",
    "        #print(v + \": p-value test Student = \" + str(st_p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ogomfIaQ3L9l",
    "outputId": "371e16f0-130b-4a92-d878-342357c9506b"
   },
   "outputs": [],
   "source": [
    "list_col_to_drop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HL3xg5CC3L9l"
   },
   "outputs": [],
   "source": [
    "df_train.drop(list_col_to_drop, axis=1, inplace=True)\n",
    "df_val.drop(list_col_to_drop, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save the df_train for using shapley value in app.py :\n",
    "df_train.to_csv(path_or_buf=\"../DATA/df_train.csv\", sep=';', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"section_3_3\"></a>\n",
    "<div style=\"border: 1px solid RGB(119, 150, 203);\" >\n",
    "    <h3 style=\"margin: auto; padding: 20px; color: RGB(119, 150, 203); \"> Split df_train to x_train and y_train (idem for df_val)</h3>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zKSlaGQv3L9m"
   },
   "outputs": [],
   "source": [
    "x_train = df_train.drop([target], axis=1)\n",
    "y_train = df_train[target]\n",
    "\n",
    "x_val = df_val.drop([target], axis=1)\n",
    "y_val = df_val[target]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 483
    },
    "id": "-tk74Qc63L9m",
    "outputId": "8fcd66f4-f098-4b35-c408-74089a45b3f0"
   },
   "outputs": [],
   "source": [
    "x_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Zi47QWuK3L9m"
   },
   "source": [
    "<a class=\"anchor\" id=\"section_3_3\"></a>\n",
    "<div style=\"border: 1px solid RGB(119, 150, 203);\" >\n",
    "    <h3 style=\"margin: auto; padding: 20px; color: RGB(119, 150, 203); \">Encoding et scaling (train et validation set)</h3>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "h6VEt0VO3L9n",
    "outputId": "75c7b1cd-ffee-4fa5-f378-9c859493e15f"
   },
   "outputs": [],
   "source": [
    "#numeric and > 2 :\n",
    "list_cont_col = x_train.select_dtypes(include=[np.number]).columns.tolist()\n",
    "list_cont_col = [col for col in list_cont_col if x_train[col].nunique() > 2]\n",
    "len(list_cont_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2pykD-jB3L9o",
    "outputId": "edba4940-2c46-47b6-e797-fc567cf5ea6b"
   },
   "outputs": [],
   "source": [
    "#numeric and <= 2 :\n",
    "list_binary_col = x_train.select_dtypes(include=[np.number]).columns.tolist()\n",
    "list_binary_col = [col for col in list_binary_col if x_train[col].nunique() <= 2]\n",
    "len(list_binary_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1eGPBG3N3L9o"
   },
   "outputs": [],
   "source": [
    "#categorical col :\n",
    "#list_cat_col = x_train.select_dtypes(include=['object']).columns.tolist()\n",
    "list_cat_col_OHE = ['CUSTOMER_GENDER']\n",
    "list_cat_col_TE =  ['marque']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nTa2wYCe3L9p",
    "outputId": "3a38cfd6-3a36-40e1-c9d1-afa642dffdf8"
   },
   "outputs": [],
   "source": [
    "len(list_cont_col) + len(list_binary_col) + len(list_cat_col_OHE) + len(list_cat_col_TE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AW_rKG3m3L9p"
   },
   "outputs": [],
   "source": [
    "sys.path.append(\"pre_processing.py\")\n",
    "a = pre_processing()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 483
    },
    "id": "5i7uzV4u3L9p",
    "outputId": "50721969-4928-46ea-a77a-d053bccec556"
   },
   "outputs": [],
   "source": [
    "#Pre processing for linear models :\n",
    "#for boosting, we encode all variable.\n",
    "x_train_bis = x_train.copy() #utilisé plus tard\n",
    "\n",
    "x_train_preprocessed = a.pre_processing(df=x_train, train=True, categorical_var_OHE= list_cat_col_OHE,\n",
    "                           categorical_var_OrdinalEncoding={}, categorical_var_TE=list_cat_col_TE, target=y_train,\n",
    "                           continious_var=list_cont_col, encoding_type_cont=MinMaxScaler())\n",
    "x_train_preprocessed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 483
    },
    "id": "VhtpQOjN3L9q",
    "outputId": "1d6c8630-392b-456e-e532-c19b1e9822c3"
   },
   "outputs": [],
   "source": [
    "x_val_bis = x_val.copy() #utilisé plus tard\n",
    "\n",
    "x_val_preprocessed = a.pre_processing(df=x_val, train=False, categorical_var_OHE= list_cat_col_OHE,\n",
    "                         categorical_var_OrdinalEncoding={}, categorical_var_TE=list_cat_col_TE, target=y_train,\n",
    "                         continious_var=list_cont_col, encoding_type_cont=MinMaxScaler())\n",
    "x_val_preprocessed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pre processing for boosting models :\n",
    "#for boosting, we only encode categorical variable.\n",
    "x_train = a.pre_processing(df=x_train, train=True, categorical_var_OHE= list_cat_col_OHE,\n",
    "                           categorical_var_OrdinalEncoding={}, categorical_var_TE=list_cat_col_TE, target=y_train,\n",
    "                           continious_var=[], encoding_type_cont=StandardScaler())\n",
    "x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_val = a.pre_processing(df=x_val, train=False, categorical_var_OHE= list_cat_col_OHE,\n",
    "                         categorical_var_OrdinalEncoding={}, categorical_var_TE=list_cat_col_TE, target=y_train,\n",
    "                         continious_var=[], encoding_type_cont=StandardScaler())\n",
    "x_val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GAaeYru48ZCi"
   },
   "source": [
    "<a class=\"anchor\" id=\"section_3_4\"></a>\n",
    "<div style=\"border: 1px solid RGB(119, 150, 203);\" >\n",
    "    <h3 style=\"margin: auto; padding: 20px; color: RGB(119, 150, 203); \">Sélection des variables - Regression logistique (RFE)</h3>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "e6vWGW1z3_Qw"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "rfe_score = {\"nb_var\" : 0,\n",
    "             \"best_score\" : 0}\n",
    "\n",
    "for i in tqdm(range(1,len(x_train_preprocessed.columns)+1)) :\n",
    "    estimator = LogisticRegression(penalty=None)\n",
    "    selector = RFE(estimator, n_features_to_select=i,step=1)\n",
    "    selector.fit(x_train_preprocessed,y_train)\n",
    "\n",
    "    x_train_preprocessed_new = x_train_preprocessed[list(selector.get_feature_names_out())]\n",
    "    estimator.fit(x_train_preprocessed_new,y_train)\n",
    "    \n",
    "    skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=20)\n",
    "    skf.get_n_splits(x_train_preprocessed_new, y_train)   \n",
    "    cross_val_score_ = mean(cross_val_score(estimator, x_train_preprocessed_new, y_train, cv=skf, scoring = \"roc_auc\")) #scoring : scoring = f1_weighted or accuracy\n",
    "\n",
    "    if cross_val_score_ > rfe_score[\"best_score\"] :\n",
    "        rfe_score[\"nb_var\"] = i\n",
    "        rfe_score[\"best_score\"] = cross_val_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YNMUAmEd8ZCi"
   },
   "outputs": [],
   "source": [
    "rfe_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZM8RSqUl8ZCj"
   },
   "outputs": [],
   "source": [
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "estimator = LogisticRegression(penalty=None)\n",
    "selector = RFE(estimator, n_features_to_select=rfe_score['nb_var'], step=1)\n",
    "selector.fit(x_train_preprocessed,y_train)\n",
    "\n",
    "print(list(selector.get_feature_names_out()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "j11B_UAy8ZCj"
   },
   "outputs": [],
   "source": [
    "# Linear model :\n",
    "x_train_preprocessed = x_train_preprocessed[list(selector.get_feature_names_out())]\n",
    "x_val_preprocessed = x_val_preprocessed[list(selector.get_feature_names_out())]\n",
    "\n",
    "# Boosting model :\n",
    "x_train = x_train[list(selector.get_feature_names_out())]\n",
    "x_val = x_val[list(selector.get_feature_names_out())]\n",
    "\n",
    "x_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GrihCvRn3L9s"
   },
   "source": [
    "<a class=\"anchor\" id=\"chapter4\"></a>\n",
    "<div style=\"display: flex; background-color: RGB(119, 150, 203);\">\n",
    "    <h1 style=\"margin: auto; padding: 30px 30px 30px 30px; color: RGB(255,255,255);\">\n",
    "            <b>Modélisation</b>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BpbAeTZ03L9s"
   },
   "source": [
    "<a class=\"anchor\" id=\"section_4_1\"></a>\n",
    "<div style=\"border: 1px solid RGB(119, 150, 203);\" >\n",
    "    <h3 style=\"margin: auto; padding: 20px; color: RGB(119, 150, 203); \">Régression logistique</h3>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hzOezMSc3L9t",
    "tags": []
   },
   "source": [
    "### Modélisation naïve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ip0Oohcv3L9t",
    "outputId": "f16f8f24-ef28-412d-dcc6-8619f31edb9d"
   },
   "outputs": [],
   "source": [
    "lr = LogisticRegression(penalty=\"none\")\n",
    "lr.fit(x_train_preprocessed, y_train)\n",
    "print(lr.score(x_train_preprocessed, y_train)) # replace scoring='accuracy' by \"recall\"  #or roc_auc\n",
    "print(lr.score(x_val_preprocessed, y_val)) # replace scoring='accuracy' by \"recall\"  #or roc_auc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#roc_auc_score\n",
    "print(roc_auc_score(y_train, lr.predict_proba(x_train_preprocessed)[:, 1])) #, multi_class='ovr'\n",
    "print(roc_auc_score(y_val, lr.predict_proba(x_val_preprocessed)[:, 1])) #, multi_class='ovr'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cross_val_score :\n",
    "from sklearn.model_selection import cross_val_score\n",
    "print(cross_val_score(lr, x_train_preprocessed, y_train, cv=5, scoring='roc_auc').mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cross_val_score stratifié : better than Classic Cross_val_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=20)\n",
    "skf.get_n_splits(x_train_preprocessed, y_train)\n",
    "\n",
    "print(cross_val_score(lr, x_train_preprocessed, y_train, cv=skf, scoring='roc_auc').mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#f1_score\n",
    "print(f1_score(y_train, lr.predict(x_train_preprocessed), average='micro', pos_label=1)) #pos_label = 1 -> number of the target #or average=binary\n",
    "print(f1_score(y_val, lr.predict(x_val_preprocessed), average='micro', pos_label=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "print(cross_val_score(lr, x_train_preprocessed, y_train, cv=5, scoring='f1_micro').mean()) #or scoring=\"f1_weighted\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cross_val_score stratifié : better than Classic Cross_val_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=20)\n",
    "skf.get_n_splits(x_train_preprocessed, y_train)\n",
    "\n",
    "print(cross_val_score(lr, x_train_preprocessed, y_train, cv=skf, scoring='f1_micro').mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hXF-vQ8P3L9w"
   },
   "source": [
    "### Optimisation des hyperparamètres"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Id1Ek_Jk3L9x"
   },
   "source": [
    "penalty = {‘l1’, ‘l2’, ‘elasticnet’, None}\n",
    "C = float, default=1.0\n",
    "class_weight= None or ‘balanced’, default=None\n",
    "solver = {‘saga’}, default=’lbfgs’\n",
    "max_iter = int, default=100\n",
    "l1_ratio = float, default=None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hhKtLpcm3L9x"
   },
   "outputs": [],
   "source": [
    "# Bayesian Optimisation (optuna) :\n",
    "warnings.filterwarnings('ignore')\n",
    "warnings.filterwarnings(action='ignore', category=DataConversionWarning)\n",
    "\n",
    "def objective(trial):\n",
    "    penalty = trial.suggest_categorical('penalty', [\"l1\", \"l2\", \"elasticnet\", \"none\"])\n",
    "    C = trial.suggest_float('C', 0.1, 5) #, step=0.1\n",
    "    class_weight = trial.suggest_categorical('class_weight', [\"balanced\", None])\n",
    "    max_iter = trial.suggest_int('max_iter', 1, 500)\n",
    "    l1_ratio = trial.suggest_float('l1_ratio', 0.001, 0.999)\n",
    "\n",
    "    model = LogisticRegression(solver='saga', penalty=penalty, C=C, class_weight=class_weight, max_iter=max_iter, l1_ratio=l1_ratio)\n",
    "\n",
    "    skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=20)\n",
    "    skf.get_n_splits(x_train_preprocessed, y_train) \n",
    "    return cross_val_score(model, x_train_preprocessed, y_train, n_jobs=-1, cv=skf, scoring='roc_auc').mean() # replace scoring='accuracy' by \"recall\"  #or auc\n",
    "\n",
    "\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RVIp8vb83L9y"
   },
   "outputs": [],
   "source": [
    "trial = study.best_trial\n",
    "print('score : {}'.format(trial.value)) # replace scoring='accuracy' by \"recall\"  #or auc\n",
    "print(\"Best hyperparameters: {}\".format(trial.params))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T740nMDn3L9z"
   },
   "source": [
    "### Ajuster le modèle avec les meilleurs hyperparamètres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eB8ywweM3L9z"
   },
   "outputs": [],
   "source": [
    "#model evaluation : r2, MSE, RMSE...\n",
    "best_model_LR = LogisticRegression(solver='saga', penalty=(trial.params)[\"penalty\"], C=(trial.params)[\"C\"], class_weight=(trial.params)[\"class_weight\"],\n",
    "                               max_iter=(trial.params)[\"max_iter\"], l1_ratio=(trial.params)[\"l1_ratio\"])\n",
    "best_model_LR.fit(x_train_preprocessed, y_train)\n",
    "\n",
    "display(best_model_LR.score(x_train_preprocessed, y_train)) # replace scoring='accuracy' by \"recall\"  #or auc\n",
    "display(best_model_LR.score(x_val_preprocessed, y_val)) # replace scoring='accuracy' by \"recall\"  #or auc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#roc_auc_score\n",
    "print(roc_auc_score(y_train, best_model_LR.predict_proba(x_train_preprocessed)[:, 1])) #, multi_class='ovr'\n",
    "print(roc_auc_score(y_val, best_model_LR.predict_proba(x_val_preprocessed)[:, 1])) #, multi_class='ovr'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cross_val_score :\n",
    "from sklearn.model_selection import cross_val_score\n",
    "print(cross_val_score(best_model_LR, x_train_preprocessed, y_train, cv=5, scoring='roc_auc').mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cross_val_score stratifié : better than Classic Cross_val_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=20)\n",
    "skf.get_n_splits(x_train_preprocessed, y_train)\n",
    "\n",
    "print(cross_val_score(best_model_LR, x_train_preprocessed, y_train, cv=skf, scoring='roc_auc').mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#f1_score\n",
    "print(f1_score(y_train, best_model_LR.predict(x_train_preprocessed), average='micro', pos_label=1)) #pos_label = 1 -> number of the target #or average=binary\n",
    "print(f1_score(y_val, best_model_LR.predict(x_val_preprocessed), average='micro', pos_label=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "print(cross_val_score(best_model_LR, x_train_preprocessed, y_train, cv=5, scoring='f1_micro').mean()) #or scoring=\"f1_weighted\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cross_val_score stratifié : better than Classic Cross_val_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=20)\n",
    "skf.get_n_splits(x_train_preprocessed, y_train)\n",
    "\n",
    "print(cross_val_score(best_model_LR, x_train_preprocessed, y_train, cv=skf, scoring='f1_micro').mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2VizHYOv3L91"
   },
   "source": [
    "<a class=\"anchor\" id=\"section_4_2\"></a>\n",
    "<div style=\"border: 1px solid RGB(119, 150, 203);\" >\n",
    "    <h3 style=\"margin: auto; padding: 20px; color: RGB(119, 150, 203); \">XGBoost</h3>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cR827KkU3L91",
    "tags": []
   },
   "source": [
    "### Modélisation naïve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "l7U7hGMn3L92",
    "outputId": "4c861188-b1aa-4bc8-d9d7-944924aa807a"
   },
   "outputs": [],
   "source": [
    "xgboost = XGBClassifier(random_state=10, tree_method='gpu_hist', predictor=\"gpu_predictor\") #, tree_method='gpu_hist'\n",
    "xgboost.fit(x_train, y_train)\n",
    "print(xgboost.score(x_train, y_train)) # replace scoring='accuracy' by \"recall\"  #or auc\n",
    "print(xgboost.score(x_val, y_val)) # replace scoring='accuracy' by \"recall\"  #or auc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N3DW4aZQ8ZCl"
   },
   "source": [
    "### roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Y-EA0DSa8ZCl",
    "outputId": "36f65b48-a57c-4597-91df-7a476dc7ff6f"
   },
   "outputs": [],
   "source": [
    "#roc_auc_score\n",
    "print(roc_auc_score(y_train, xgboost.predict_proba(x_train)[:, 1])) #, multi_class='ovr'\n",
    "print(roc_auc_score(y_val, xgboost.predict_proba(x_val)[:, 1])) #, multi_class='ovr'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "C_GTFSib8ZCl",
    "outputId": "e1ca625f-60bd-4a02-97ca-3a9861b7f266"
   },
   "outputs": [],
   "source": [
    "#Cross_val_score :\n",
    "from sklearn.model_selection import cross_val_score\n",
    "print(cross_val_score(xgboost, x_train,y_train, cv=5, scoring='roc_auc').mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cross_val_score stratifié : better than Classic Cross_val_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=20)\n",
    "skf.get_n_splits(x_train, y_train)\n",
    "\n",
    "print(cross_val_score(xgboost, x_train, y_train, cv=skf, scoring='roc_auc').mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cyEYI81W8ZCl"
   },
   "source": [
    "### f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "piughlrb8ZCl",
    "outputId": "a4e33081-33d5-429c-c509-3e4840033038"
   },
   "outputs": [],
   "source": [
    "#f1_score\n",
    "print(f1_score(y_train, xgboost.predict(x_train), average='micro', pos_label=1)) #pos_label = 1 -> number of the target #or average=binary\n",
    "print(f1_score(y_val, xgboost.predict(x_val), average='micro', pos_label=1)) #or weighted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JyFUTMNv8ZCl",
    "outputId": "19d2e22c-a629-45ec-9f8f-c4cbc50243e3"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "print(cross_val_score(xgboost, x_train, y_train, cv=5, scoring='f1_micro').mean()) #or scoring=\"f1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cross_val_score stratifié : better than Classic Cross_val_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=20)\n",
    "skf.get_n_splits(x_train, y_train)\n",
    "\n",
    "print(cross_val_score(xgboost, x_train, y_train, cv=skf, scoring='f1_micro').mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Jab9FLIl3L94"
   },
   "source": [
    "### Optimisation des hyperparamètres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TeGKr_Xj3L95",
    "outputId": "2e7ba766-11af-4a3f-b825-0bfafc0c4d5e"
   },
   "outputs": [],
   "source": [
    "#Bayesian Optimisation (optuna) :\n",
    "#try to find an option where it can show us a rank of best hyper parameters options (from best to the worst)\n",
    "def objective(trial):\n",
    "    #random_state = trial.suggest_int('random_state', 1,100)\n",
    "    n_estimators = trial.suggest_int('n_estimators', 1,2000) #nb of tree\n",
    "    max_depth = trial.suggest_int('max_depth', 1, 10) #profondeur\n",
    "    min_child_weight = trial.suggest_int('min_child_weight', 1, 10)\n",
    "    learning_rate = trial.suggest_float('learning_rate', 0.01, 0.7)\n",
    "    min_split_loss = trial.suggest_float('min_split_loss', 0, 5)\n",
    "    colsample_bytree = trial.suggest_float('colsample_bytree', 0.1, 1) #min leaf of each tree\n",
    "    subsample = trial.suggest_float('subsample', 0.1, 1)\n",
    "\n",
    "\n",
    "    model = XGBClassifier(random_state=10, n_estimators=n_estimators, max_depth=max_depth, min_child_weight=min_child_weight,\n",
    "                          learning_rate=learning_rate, min_split_loss=min_split_loss, colsample_bytree=colsample_bytree, subsample=subsample,\n",
    "                          n_jobs=-1, tree_method='gpu_hist', predictor=\"gpu_predictor\") #, tree_method='gpu_hist'\n",
    "\n",
    "    skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=20)\n",
    "    skf.get_n_splits(x_train, y_train) \n",
    "    return cross_val_score(model, x_train, y_train, n_jobs=-1, cv=skf, scoring='f1_micro').mean() # or f1_weighted\n",
    "\n",
    "\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "paPtvztI3L96",
    "outputId": "5346243f-ee07-470c-838e-b8796b6f5504"
   },
   "outputs": [],
   "source": [
    "trial = study.best_trial\n",
    "print('score: {}'.format(trial.value))\n",
    "print(\"Best hyperparameters: {}\".format(trial.params))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XP-EzdN-3L96"
   },
   "source": [
    "### Ajuster le modèle avec les meilleurs hyperparamètres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rNx3V68ZW5y8"
   },
   "outputs": [],
   "source": [
    "#model evaluation : accuracy, precision...\n",
    "best_model_xgboost = XGBClassifier(random_state=10, n_estimators=(trial.params)[\"n_estimators\"], max_depth=(trial.params)[\"max_depth\"],\n",
    "                          min_child_weight=(trial.params)[\"min_child_weight\"], learning_rate=(trial.params)[\"learning_rate\"],\n",
    "                          min_split_loss=(trial.params)[\"min_split_loss\"],colsample_bytree=(trial.params)[\"colsample_bytree\"],\n",
    "                          subsample=(trial.params)[\"subsample\"], n_jobs=-1, tree_method='gpu_hist', predictor=\"gpu_predictor\") #, tree_method='gpu_hist'\n",
    "best_model_xgboost.fit(x_train, y_train)\n",
    "\n",
    "display(best_model_xgboost.score(x_train, y_train)) # replace scoring='accuracy' by \"recall\"  #or auc\n",
    "display(best_model_xgboost.score(x_val, y_val)) # replace scoring='accuracy' by \"recall\"  #or auc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dW0lkCtu8ZCm"
   },
   "source": [
    "### roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "phi9JCmF8ZCm",
    "outputId": "d6f54348-fefc-4906-d5f9-4f4fda65db77"
   },
   "outputs": [],
   "source": [
    "#roc_auc_score\n",
    "print(roc_auc_score(y_train, best_model_xgboost.predict_proba(x_train)[:, 1])) #, multi_class='ovr'\n",
    "print(roc_auc_score(y_val, best_model_xgboost.predict_proba(x_val)[:, 1])) #, multi_class='ovr'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "but46nXz8ZCm",
    "outputId": "926ef8e7-3f28-4fc8-f5e6-9fee2e73d8e0"
   },
   "outputs": [],
   "source": [
    "#Cross_val_score :\n",
    "from sklearn.model_selection import cross_val_score\n",
    "print(cross_val_score(best_model_xgboost, x_train,y_train, cv=5, scoring='roc_auc').mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cross_val_score stratifié : better than Classic Cross_val_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=20)\n",
    "skf.get_n_splits(x_train, y_train)\n",
    "\n",
    "print(cross_val_score(best_model_xgboost, x_train, y_train, cv=skf, scoring='roc_auc').mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vK1Kkvj18ZCm"
   },
   "source": [
    "### f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7AgSp7o_8ZCm",
    "outputId": "702e2b68-ce95-4065-fc59-2e50945de017"
   },
   "outputs": [],
   "source": [
    "#f1_score\n",
    "print(f1_score(y_train, best_model_xgboost.predict(x_train), average='micro', pos_label=1)) #pos_label = 1 -> number of the target #or average=binary\n",
    "print(f1_score(y_val, best_model_xgboost.predict(x_val), average='micro', pos_label=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mrZNQsmp8ZCn",
    "outputId": "392a84b1-ec7e-458f-f1fe-e2d99429d272"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "print(cross_val_score(best_model_xgboost, x_train, y_train, cv=5, scoring='f1_micro').mean()) #or scoring=\"f1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cross_val_score stratifié : better than Classic Cross_val_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=20)\n",
    "skf.get_n_splits(x_train, y_train)\n",
    "\n",
    "print(cross_val_score(best_model_xgboost, x_train, y_train, cv=skf, scoring='f1_micro').mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YooSZf5D3L99"
   },
   "source": [
    "<a class=\"anchor\" id=\"section_4_3\"></a>\n",
    "<div style=\"border: 1px solid RGB(119, 150, 203);\" >\n",
    "    <h3 style=\"margin: auto; padding: 20px; color: RGB(119, 150, 203); \">LightGBM</h3>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ELzDtrhN3L9-"
   },
   "outputs": [],
   "source": [
    "!pip install lightgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vaYqJDpH3L9-",
    "outputId": "2f7065a9-42b2-4758-c880-3b4d1def4600"
   },
   "outputs": [],
   "source": [
    "lgbm = LGBMClassifier(random_state=15)  #, device='gpu' or 'cuda' or device_type=\"gpu\"\n",
    "lgbm.fit(x_train, y_train)\n",
    "print(lgbm.score(x_train, y_train))  #or auc\n",
    "print(lgbm.score(x_val, y_val))  #or auc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VF5SeSU63L-A"
   },
   "source": [
    "Diff metrics (scoring) : accuracy, average_precision, precision, recall, f1(for binary targets) , roc_auc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IBzLj_rT8ZCn"
   },
   "source": [
    "### roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "601EPgEi8ZCn"
   },
   "outputs": [],
   "source": [
    "#roc_auc_score\n",
    "print(roc_auc_score(y_train, lgbm.predict_proba(x_train)[:, 1])) #, multi_class='ovr'\n",
    "print(roc_auc_score(y_val, lgbm.predict_proba(x_val)[:, 1])) #, multi_class='ovr'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lOO7SRpY8ZCn"
   },
   "outputs": [],
   "source": [
    "#Cross_val_score :\n",
    "from sklearn.model_selection import cross_val_score\n",
    "print(cross_val_score(lgbm, x_train,y_train, cv=5, scoring='roc_auc').mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cross_val_score stratifié : better than Classic Cross_val_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=20)\n",
    "skf.get_n_splits(x_train, y_train)\n",
    "\n",
    "print(cross_val_score(lgbm, x_train, y_train, cv=skf, scoring='roc_auc').mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fG-4qMDC8ZCn"
   },
   "source": [
    "### f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GbA-CmE88ZCn"
   },
   "outputs": [],
   "source": [
    "#f1_score\n",
    "print(f1_score(y_train, lgbm.predict(x_train), average='weighted', pos_label=1)) #pos_label = 1 -> number of the target #or average=binary\n",
    "print(f1_score(y_val, lgbm.predict(x_val), average='weighted', pos_label=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_l3sJZe08ZCo"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "print(cross_val_score(lgbm, x_train, y_train, cv=5, scoring='f1_weighted').mean()) #or scoring=\"f1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cross_val_score stratifié : better than Classic Cross_val_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=20)\n",
    "skf.get_n_splits(x_train, y_train)\n",
    "\n",
    "print(cross_val_score(lgbm, x_train, y_train, cv=skf, scoring='f1_micro').mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q3HqNE2T3L-B"
   },
   "source": [
    "### Optimisation des hyperparamètres"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "id": "uezp50y_3L-B"
   },
   "source": [
    "max_depth = trial.suggest_categorical('max_depth', [5, 6, 7, 8, 9, 10, 12, 14, 16, 18, 20, 23, 25, 28, 30, 40, 50, None]) #profondeur\n",
    "learning_rate = trial.suggest_categorical('learning_rate', [0.01,0.02, 0.03, 0.04, 0.05, 0.06, 0.07, 0.08, 0.09, 0.1])\n",
    "n_estimators = trial.suggest_int('n_estimators', 1,1001, step=20) #nb of tree\n",
    "boosting_type = trial.suggest_categorical('boosting_type', [\"gbdt\", \"dart\"])\n",
    "num_leaves = trial.suggest_int('num_leave', 10,201,step=5)\n",
    "#feature_fraction = trial.suggest_float('feature_fraction', 0.1,0.999)\n",
    "subsample = trial.suggest_float('subsample', 0.1,0.999)\n",
    "reg_alpha = trial.suggest_float('reg_alpha', 0.001,0.999)\n",
    "reg_lambda = trial.suggest_float('reg_lambda', 0.001,0.999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2QNNGSLF3L-C"
   },
   "outputs": [],
   "source": [
    "#Bayesian Optimisation (optuna) :\n",
    "def objective(trial):\n",
    "    max_depth = trial.suggest_int('max_depth', 1, 10) #profondeur\n",
    "    num_leaves = trial.suggest_int('num_leaves', 2,201)\n",
    "    min_child_samples = trial.suggest_int('min_child_samples', 10,201)\n",
    "    #colsample_bytree = trial.suggest_float('colsample_bytree', 0.1,1)\n",
    "    subsample = trial.suggest_float('subsample', 0.1, 1)\n",
    "\n",
    "    learning_rate = trial.suggest_float('learning_rate', 0.01, 0.7)\n",
    "    n_estimators = trial.suggest_int('n_estimators', 1, 2000) #nb of tree\n",
    "\n",
    "    model = LGBMClassifier(random_state=10, max_depth=max_depth, num_leaves=num_leaves, min_child_samples=min_child_samples,\n",
    "                           subsample=subsample,\n",
    "                           learning_rate=learning_rate, n_estimators=n_estimators)  #, device='gpu' or \"cuda\"\n",
    "    #colsample_bytree=colsample_bytree\n",
    "\n",
    "    skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=20)\n",
    "    skf.get_n_splits(x_train, y_train) \n",
    "    return cross_val_score(model, x_train, y_train, n_jobs=-1, cv=skf, scoring='f1_weighted').mean()  #or auc #or recall #or f1\n",
    "\n",
    "\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "x10AbGLj3L-C"
   },
   "outputs": [],
   "source": [
    "trial = study.best_trial\n",
    "print('score: {}'.format(trial.value))  #or auc\n",
    "print(\"Best hyperparameters: {}\".format(trial.params))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KvJT30_J3L-D"
   },
   "source": [
    "### Ajuster le modèle avec les meilleurs hyperparamètres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KLtLVE4x3L-E"
   },
   "outputs": [],
   "source": [
    "#model evaluation : r2, MSE, RMSE...\n",
    "best_model_lgbm = LGBMClassifier(random_state=10, max_depth=(trial.params)['max_depth'], num_leaves=(trial.params)['num_leaves'],\n",
    "                           min_child_samples=(trial.params)['min_child_samples'],\n",
    "                           subsample=(trial.params)['subsample'],learning_rate=(trial.params)['learning_rate'],\n",
    "                           n_estimators=(trial.params)['n_estimators'])  #, device='gpu' or \"cuda\" #colsample_bytree=(trial.params)['colsample_bytree'],\n",
    "\n",
    "best_model_lgbm.fit(x_train, y_train)\n",
    "display(best_model_lgbm.score(x_train, y_train))  #or auc\n",
    "display(best_model_lgbm.score(x_val, y_val)) #or auc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W-t-c7AX8ZCo"
   },
   "source": [
    "### roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YY--psVk8ZCo"
   },
   "outputs": [],
   "source": [
    "#roc_auc_score\n",
    "print(roc_auc_score(y_train, best_model_lgbm.predict_proba(x_train)[:, 1])) #, multi_class='ovr'\n",
    "print(roc_auc_score(y_val, best_model_lgbm.predict_proba(x_val)[:, 1])) #, multi_class='ovr'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EIiflf588ZCp"
   },
   "outputs": [],
   "source": [
    "#Cross_val_score :\n",
    "from sklearn.model_selection import cross_val_score\n",
    "print(cross_val_score(best_model_lgbm, x_train,y_train, cv=5, scoring='roc_auc').mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cross_val_score stratifié : better than Classic Cross_val_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=20)\n",
    "skf.get_n_splits(x_train, y_train)\n",
    "\n",
    "print(cross_val_score(best_model_lgbm, x_train, y_train, cv=skf, scoring='roc_auc').mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EpTQ1PDB8ZCp"
   },
   "source": [
    "### f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gmYuNgvP8ZCp"
   },
   "outputs": [],
   "source": [
    "#f1_score\n",
    "print(f1_score(y_train, best_model_lgbm.predict(x_train), average='weighted', pos_label=1)) #pos_label = 1 -> number of the target #or average=binary\n",
    "print(f1_score(y_val, best_model_lgbm.predict(x_val), average='weighted', pos_label=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4N3jkzH48ZCp"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "print(cross_val_score(best_model_lgbm, x_train, y_train, cv=5, scoring='f1_weighted').mean()) #or scoring=\"f1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cross_val_score stratifié : better than Classic Cross_val_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=20)\n",
    "skf.get_n_splits(x_train, y_train)\n",
    "\n",
    "print(cross_val_score(best_model_lgbm, x_train, y_train, cv=skf, scoring='f1_micro').mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ee7TkFLX3L-O"
   },
   "source": [
    "<a class=\"anchor\" id=\"chapter5\"></a>\n",
    "<div style=\"display: flex; background-color: RGB(119, 150, 203);\">\n",
    "    <h1 style=\"margin: auto; padding: 30px 30px 30px 30px; color: RGB(255,255,255);\">\n",
    "            <b>Choix du modèle final : XGBoost</b>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Bmd1zAMZ3L-P"
   },
   "source": [
    "<a class=\"anchor\" id=\"section_5_1\"></a>\n",
    "<div style=\"border: 1px solid RGB(119, 150, 203);\" >\n",
    "    <h3 style=\"margin: auto; padding: 20px; color: RGB(119, 150, 203); \">Analyse des résultats (on df_val/test)</h3>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X4gD8vXL3L-P"
   },
   "source": [
    "### Confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 573
    },
    "id": "4SeglnOj3L-P",
    "outputId": "7eca2a19-7f53-4eb5-d25f-2ad0de4b0277"
   },
   "outputs": [],
   "source": [
    "# prediction on val\n",
    "y_pred = best_model_xgboost.predict(x_val)\n",
    "\n",
    "# compute the confusion matrix\n",
    "cm = confusion_matrix(y_val,y_pred)\n",
    "\n",
    "#Plot the confusion matrix.\n",
    "f, ax=plt.subplots(figsize=(6,6))\n",
    "sns.heatmap(cm,annot=True,linewidths=0.5,linecolor=\"red\",fmt=\".0f\",ax=ax)\n",
    "plt.ylabel('Actual',fontsize=13)\n",
    "plt.xlabel('Prediction',fontsize=13)\n",
    "plt.title('Confusion Matrix on y_val',fontsize=17)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "a7ajtcvExY5_",
    "outputId": "e814f8ba-7233-4313-d00a-69f825915c07"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(y_val, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f6hVs5T63L-P"
   },
   "source": [
    "### ROC-AUC\n",
    "\n",
    "ROC Curve - One vs Rest (OvR)\n",
    "\n",
    "Compares each class with the rest of the classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AYHEfuhi3L-Q"
   },
   "outputs": [],
   "source": [
    "def calculate_tpr_fpr(y_real, y_pred):\n",
    "    '''\n",
    "    Calculates the True Positive Rate (tpr) and the True Negative Rate (fpr) based on real and predicted observations\n",
    "\n",
    "    Args:\n",
    "        y_real: The list or series with the real classes\n",
    "        y_pred: The list or series with the predicted classes\n",
    "\n",
    "    Returns:\n",
    "        tpr: The True Positive Rate of the classifier\n",
    "        fpr: The False Positive Rate of the classifier\n",
    "    '''\n",
    "\n",
    "    # Calculates the confusion matrix and recover each element\n",
    "    cm = confusion_matrix(y_real, y_pred)\n",
    "    TN = cm[0, 0]\n",
    "    FP = cm[0, 1]\n",
    "    FN = cm[1, 0]\n",
    "    TP = cm[1, 1]\n",
    "\n",
    "    # Calculates tpr and fpr\n",
    "    tpr =  TP/(TP + FN) # sensitivity - true positive rate\n",
    "    fpr = 1 - TN/(TN+FP) # 1-specificity - false positive rate\n",
    "\n",
    "    return tpr, fpr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nAvvhJjC3L-Q"
   },
   "outputs": [],
   "source": [
    "def get_all_roc_coordinates(y_real, y_proba):\n",
    "    '''\n",
    "    Calculates all the ROC Curve coordinates (tpr and fpr) by considering each point as a threshold for the predicion of the class.\n",
    "\n",
    "    Args:\n",
    "        y_real: The list or series with the real classes.\n",
    "        y_proba: The array with the probabilities for each class, obtained by using the `.predict_proba()` method.\n",
    "\n",
    "    Returns:\n",
    "        tpr_list: The list of TPRs representing each threshold.\n",
    "        fpr_list: The list of FPRs representing each threshold.\n",
    "    '''\n",
    "    tpr_list = [0]\n",
    "    fpr_list = [0]\n",
    "    for i in range(len(y_proba)):\n",
    "        threshold = y_proba[i]\n",
    "        y_pred = y_proba >= threshold\n",
    "        tpr, fpr = calculate_tpr_fpr(y_real, y_pred)\n",
    "        tpr_list.append(tpr)\n",
    "        fpr_list.append(fpr)\n",
    "    return tpr_list, fpr_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "whm0IIgI3L-R"
   },
   "outputs": [],
   "source": [
    "def plot_roc_curve(tpr, fpr, scatter = True, ax = None):\n",
    "    '''\n",
    "    Plots the ROC Curve by using the list of coordinates (tpr and fpr).\n",
    "\n",
    "    Args:\n",
    "        tpr: The list of TPRs representing each coordinate.\n",
    "        fpr: The list of FPRs representing each coordinate.\n",
    "        scatter: When True, the points used on the calculation will be plotted with the line (default = True).\n",
    "    '''\n",
    "    if ax == None:\n",
    "        plt.figure(figsize = (5, 5))\n",
    "        ax = plt.axes()\n",
    "\n",
    "    if scatter:\n",
    "        sns.scatterplot(x = fpr, y = tpr, ax = ax)\n",
    "    sns.lineplot(x = fpr, y = tpr, ax = ax)\n",
    "    sns.lineplot(x = [0, 1], y = [0, 1], color = 'green', ax = ax)\n",
    "    plt.xlim(-0.05, 1.05)\n",
    "    plt.ylim(-0.05, 1.05)\n",
    "    plt.xlabel(\"False Positive Rate\")\n",
    "    plt.ylabel(\"True Positive Rate\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tJi7ZMg73L-R"
   },
   "outputs": [],
   "source": [
    "y_pred = best_model_xgboost.predict(x_val)\n",
    "y_proba = best_model_xgboost.predict_proba(x_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hPT594gQ3L-R",
    "outputId": "a837b731-be0f-428b-eb52-2fea5cfa67e1"
   },
   "outputs": [],
   "source": [
    "classes = best_model_xgboost.classes_\n",
    "classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plots the Probability Distributions and the ROC Curves One vs Rest\n",
    "plt.figure(figsize = (12, 8))\n",
    "bins = [i/20 for i in range(20)] + [1]\n",
    "classes = best_model_xgboost.classes_\n",
    "roc_auc_ovr = {}\n",
    "for i in range(len(classes)):\n",
    "    # Gets the class\n",
    "    c = classes[i]\n",
    "\n",
    "    # Prepares an auxiliar dataframe to help with the plots\n",
    "    df_aux = x_val.copy()\n",
    "    df_aux['class'] = [1 if y == c else 0 for y in y_val]\n",
    "    df_aux['prob'] = y_proba[:, i]\n",
    "    df_aux = df_aux.reset_index(drop = True)\n",
    "\n",
    "    # Plots the probability distribution for the class and the rest\n",
    "    ax = plt.subplot(2, 4, i+1)\n",
    "    sns.histplot(x = \"prob\", data = df_aux, hue = 'class', color = 'b', ax = ax, bins = bins)\n",
    "    ax.set_title(c)\n",
    "    ax.legend([f\"Class: {c}\", \"Rest\"])\n",
    "    ax.set_xlabel(f\"P(x = {c})\")\n",
    "\n",
    "    # Calculates the ROC Coordinates and plots the ROC Curves\n",
    "    ax_bottom = plt.subplot(2, 4, i+5)\n",
    "    tpr, fpr = get_all_roc_coordinates(df_aux['class'], df_aux['prob'])\n",
    "    plot_roc_curve(tpr, fpr, scatter = False, ax = ax_bottom)\n",
    "    ax_bottom.set_title(\"ROC Curve OvR\")\n",
    "\n",
    "    # Calculates the ROC AUC OvR\n",
    "    roc_auc_ovr[c] = roc_auc_score(df_aux['class'], df_aux['prob'])\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 472
    },
    "id": "ibD9mGZw3c-d",
    "outputId": "9ebb6b39-1bd8-4f01-d893-bdfd090a0913"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "fpr_train_XGB, tpr_train_XGB, thresholds_train_XGB = roc_curve(y_train, best_model_xgboost.predict_proba(x_train)[:,1])\n",
    "roc_auc_train_XGB = auc(fpr_train_XGB, tpr_train_XGB)\n",
    "\n",
    "\n",
    "fpr_val_XGB, tpr_val_XGB, thresholds_val_XGB = roc_curve(y_val, best_model_xgboost.predict_proba(x_val)[:,1])\n",
    "roc_auc_val_XGB = auc(fpr_val_XGB, tpr_val_XGB)\n",
    "\n",
    "\n",
    "plt.figure()\n",
    "lw = 2\n",
    "plt.plot(fpr_train_XGB, tpr_train_XGB, color='darkorange',\n",
    "         lw=lw, label='Train - ROC curve (area = %0.3f)' % roc_auc_train_XGB)\n",
    "\n",
    "plt.plot(fpr_val_XGB, tpr_val_XGB, color='darkgreen',\n",
    "         lw=lw, label='Val - ROC curve (area = %0.3f)' % roc_auc_val_XGB)\n",
    "\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
    "\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.title('Comparaison courbes ROC Train/Val')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lK8rOz9x3L-T",
    "outputId": "870616dd-469a-44d4-8113-d75fc5e96ee8"
   },
   "outputs": [],
   "source": [
    "# Displays the ROC AUC for each class\n",
    "avg_roc_auc = 0\n",
    "i = 0\n",
    "for k in roc_auc_ovr:\n",
    "    avg_roc_auc += roc_auc_ovr[k]\n",
    "    i += 1\n",
    "    print(f\"{k} ROC AUC OvR: {roc_auc_ovr[k]:.4f}\")\n",
    "print(f\"average ROC AUC OvR: {avg_roc_auc/i:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pctFcBUL3L-T",
    "outputId": "36ffaef6-9f14-4343-afd4-681817da0382"
   },
   "outputs": [],
   "source": [
    "# Compares with sklearn (average only)\n",
    "# \"Macro\" average = unweighted mean\n",
    "roc_auc_score(y_val, y_proba[:,1], labels = classes, multi_class = 'ovo', average = 'macro')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-YI2QRfd3L-T"
   },
   "source": [
    "### Precision/Recall curve :\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TNJBWX4R3L-U"
   },
   "outputs": [],
   "source": [
    "#Precision/Recall curve :\n",
    "y_train_pred = best_model_xgboost.predict(x_train)\n",
    "y_train_proba = best_model_xgboost.predict_proba(x_train)\n",
    "\n",
    "y_val_pred = best_model_xgboost.predict(x_val)\n",
    "y_val_proba = best_model_xgboost.predict_proba(x_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 472
    },
    "id": "RvE7Lyo03L-U",
    "outputId": "c1fba52a-fde7-472f-96fe-0933096c4f8d"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import average_precision_score\n",
    "\n",
    "precision_train, recall_train, thresholds_train = precision_recall_curve(y_train,\n",
    "                                                                         y_train_proba[:, 1])\n",
    "precision_val, recall_val, thresholds_val = precision_recall_curve(y_val,\n",
    "                                                                      y_val_proba[:, 1])\n",
    "plt.figure()\n",
    "lw = 2\n",
    "plt.plot(recall_train,precision_train, color='darkorange',\n",
    "         lw=lw, label='Train')\n",
    "\n",
    "plt.plot(recall_val,precision_val, color='darkgreen',\n",
    "         lw=lw, label='Val')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.title('Comparaison courbe PRECISION / RAPPEL (TRAIN / VAL)')\n",
    "plt.legend(loc=\"upper right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XBhladPz3L-U"
   },
   "outputs": [],
   "source": [
    "## Choix du seuil - Optimiser le recall pour toper le plus de churner\n",
    "table_choix_seuil = pd.DataFrame()\n",
    "table_choix_seuil[\"SEUIL\"] = [0] + list(thresholds_train)\n",
    "table_choix_seuil[\"Precision_train\"] = precision_train\n",
    "table_choix_seuil[\"Recall_train\"] = recall_train\n",
    "table_choix_seuil.sort_values(by = \"SEUIL\", axis=0, ascending=False, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 419
    },
    "id": "X6l4_R8k3L-V",
    "outputId": "78f90fc5-928b-44e8-89ce-7e06f21000bc"
   },
   "outputs": [],
   "source": [
    "table_choix_seuil = pd.DataFrame(table_choix_seuil)\n",
    "table_choix_seuil[table_choix_seuil[\"Recall_train\"]>=0.95].sort_values(by = \"Recall_train\", axis=0, ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GC6EG219gcOm",
    "outputId": "188399e4-d7da-4324-97e1-52a31b272f34"
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from tqdm.notebook import tqdm_notebook\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import precision_score\n",
    "\n",
    "best_seuil = {\"seuil\":0,\n",
    "              \"recall\" : 0,\n",
    "              \"precision\": 0,\n",
    "              \"tot_perte_sans_model\" : 0,\n",
    "              \"tot_perte_avec_model\": 0,\n",
    "              \"profit_net_sauve_grace_au_model_sur_1an\" : 0}\n",
    "\n",
    "#objectif : limiter la perte de bénéfice sur les 12 prochains mois grace au modèle, pour ca on propose une offre de reduc de 3euros sur leur forfait pour 1 an\n",
    "#ex : Ici, le modele nous a permis de limiter la perte de benefice (ou profit) de 94953.59 euros sur 1 an (pour environs 9800 clients)\n",
    "#cela veut dire que si on garde les churner 1 an de plus et bien : au lieu d'avoir une perte de benefice de 302486.4 (pertes sans modele), on ne perd plus que 207532.8 euros (pertes avec modele)\n",
    "\n",
    "#forfait mensuel pour 1 client = 18 euros\n",
    "#profit mensuel par client (%)= 0.4\n",
    "#cout campagne d'offre de reduction pour 1 client pour 1 mois(campagne pub + offre de reduction) = 3 euros\n",
    "#coût de l'offre de reduction sur 1 an = 12*3\n",
    "prix_forfait_mensuel_par_client = x_train_bis.AVERAGE_CHARGE_6M.mean()/6\n",
    "profit_mensuel_par_forfait_par_client_en_porucent = 0.4\n",
    "profit_mensuel_par_forfait_par_client = profit_mensuel_par_forfait_par_client_en_porucent*prix_forfait_mensuel_par_client\n",
    "cout_campagne_offre_par_client_par_mois = (x_train_bis.AVERAGE_CHARGE_6M.mean()/6)*0.2\n",
    "\n",
    "for i in tqdm(table_choix_seuil['SEUIL']) :\n",
    "    seuil = i\n",
    "    y_train_predict_seuil = (y_train_proba[:, 1]>=seuil)*1\n",
    "\n",
    "    Confusion_matrix_train = confusion_matrix(y_train, y_train_predict_seuil)\n",
    "    Confusion_matrix_train = pd.DataFrame(Confusion_matrix_train)\n",
    "\n",
    "    #calcul :\n",
    "    #nb d'euros économisés pour 1 mois (faire *12 si on veut pour tous les ans)\n",
    "    Tot_OBS_1 = Confusion_matrix_train[1][1] + Confusion_matrix_train[0][1] #Tot_OBS_1 = observation total de tous les churner\n",
    "    TP = Confusion_matrix_train[1][1] #TP =true positive\n",
    "    Tot_PRED_1 = Confusion_matrix_train[1][0] + Confusion_matrix_train[1][1] #Tot_PRED_1 = observation total de tous les churner prédit par le modèle\n",
    "\n",
    "    tot_perte_avec_model = Tot_OBS_1*profit_mensuel_par_forfait_par_client - (TP*profit_mensuel_par_forfait_par_client - (Tot_PRED_1*cout_campagne_offre_par_client_par_mois))\n",
    "    tot_perte_sans_model = Tot_OBS_1*profit_mensuel_par_forfait_par_client\n",
    "    profit_net_sauve_grace_au_model_sur_1an = (tot_perte_sans_model - tot_perte_avec_model)*12\n",
    "\n",
    "    if profit_net_sauve_grace_au_model_sur_1an > best_seuil[\"profit_net_sauve_grace_au_model_sur_1an\"] :\n",
    "        best_seuil[\"seuil\"] = seuil\n",
    "        best_seuil[\"recall\"] = str(recall_score(y_train, y_train_predict_seuil))\n",
    "        best_seuil[\"precision\"] = str(precision_score(y_train, y_train_predict_seuil))\n",
    "        best_seuil[\"tot_perte_sans_model\"] = tot_perte_sans_model*12\n",
    "        best_seuil[\"tot_perte_avec_model\"] = tot_perte_avec_model*12\n",
    "        best_seuil[\"profit_net_sauve_grace_au_model_sur_1an\"] = profit_net_sauve_grace_au_model_sur_1an\n",
    "\n",
    "best_seuil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4nCAAVf13L-V",
    "outputId": "67fed29a-fc15-4034-a1cb-8591ab494646"
   },
   "outputs": [],
   "source": [
    "# Application du seuil selectionné au jeu d'apprentissage\n",
    "\n",
    "seuil = 0.48784318566322327\n",
    "y_train_predict_seuil = (y_train_proba[:, 1]>=seuil)*1\n",
    "\n",
    "print(\"Metrique pour le jeu de données train : \")\n",
    "print(\"\\n Recall : \" + str(recall_score(y_train, y_train_predict_seuil)))\n",
    "\n",
    "print(\"\\n Précision : \" + str(precision_score(y_train, y_train_predict_seuil)))\n",
    "Confusion_matrix_app = confusion_matrix(y_train, y_train_predict_seuil)\n",
    "print(pd.DataFrame(Confusion_matrix_app))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PM4NxJ9u8ZCr"
   },
   "outputs": [],
   "source": [
    "## Choix du seuil - Optimiser le recall/precision pour avoir le meilleur profit sur le val\n",
    "table_choix_seuil_val = pd.DataFrame()\n",
    "table_choix_seuil_val[\"SEUIL\"] = [0] + list(thresholds_val)\n",
    "table_choix_seuil_val[\"Precision_val\"] = precision_val\n",
    "table_choix_seuil_val[\"Recall_val\"] = recall_val\n",
    "table_choix_seuil_val.sort_values(by = \"SEUIL\", axis=0, ascending=False, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 419
    },
    "id": "VPF6CPwN8ZCr",
    "outputId": "617840c7-ce49-433f-a179-2120074fc94a"
   },
   "outputs": [],
   "source": [
    "table_choix_seuil_val = pd.DataFrame(table_choix_seuil_val)\n",
    "table_choix_seuil_val"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Objectif : limiter la perte de bénéfice sur les 12 prochains mois grace au modèle. Avoir un Gain_sur_perte_1an le plus élevé possible.\n",
    "# Solution : proposer une remise de 1 euro par mois pendant 1an aux potentiel churners.\n",
    "\n",
    "\n",
    "# Gain sur perte sur 1 mois :\n",
    "\n",
    "nb_recharge_moyenne_1mois_1client = x_val_bis[\"AVERAGE_CHARGE_6M\"].mean()/6\n",
    "prix_1recharge = 5\n",
    "CA_1client_1mois = nb_recharge_moyenne_1mois_1client*prix_1recharge\n",
    "profit_1client_1mois = 0.4*CA_1client_1mois\n",
    "nb_client_churner_obs = df_val[df_val[\"AFTERGRACE_FLAG\"]==1].shape[0]\n",
    "Profit_total_du_mois_actuel = len(x_df)*profit_1client_1mois  #profit au moment où les churners ne sont pas encore parties\n",
    "\n",
    "Profit_total_perdu_sans_model = Profit_total_du_mois_actuel - (profit_1client_1mois*nb_client_churner_obs)\n",
    "\n",
    "remise_pour_1churner_predit_1mois = 1\n",
    "Profit_total_perdu_avec_model = Profit_total_du_mois_actuel - [[(true_pos + false_pos)*remise_pour_1churner_predit_1mois] + (false_negative*profit_1client_1mois) - (true_positive*profit_1client_1mois)]\n",
    "\n",
    "\n",
    "Gain_sur_perte_1mois = Profit_total_perdu_sans_model - Profit_total_perdu_avec_model \n",
    "Gain_sur_perte_1an = Gain_sur_perte_1mois*12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Application au jeu de val\n",
    "\n",
    "# Objectif : limiter la perte de bénéfice sur les 12 prochains mois grace au modèle. Avoir un Gain_sur_perte_1an le plus élevé possible.\n",
    "# Solution : proposer une remise de 1 euro par mois pendant 1an aux potentiel churners.\n",
    "\n",
    "def choose_best_seuil(x_df, y_df, prix_1recharge=5, pourcentage_profit=0.4, remise_pour_1churner_predit_1mois=1, table_choix_seuil=table_choix_seuil_val):\n",
    "    y_proba = best_model_xgboost.predict_proba(x_df)\n",
    "    \n",
    "    best_seuil = {\"seuil\": 0,\n",
    "                \"recall\" : 0,\n",
    "                \"precision\": 0,\n",
    "                \"Profit_total_mois_prochain_sans_model_1mois\" : 0,\n",
    "                \"Profit_total_mois_prochain_avec_model_1mois\": 0,\n",
    "                \"Gain_de_profit_grace_model_1mois\" : 0}\n",
    "\n",
    "\n",
    "    # Gain sur perte sur 1 mois :\n",
    "    nb_recharge_moyenne_1mois_1client = x_df[\"AVERAGE_CHARGE_6M\"].mean()/6\n",
    "    CA_1client_1mois = nb_recharge_moyenne_1mois_1client*prix_1recharge\n",
    "    profit_1client_1mois = pourcentage_profit*CA_1client_1mois\n",
    "    Profit_total_du_mois_actuel = len(x_df)*profit_1client_1mois #profit au moment où les churners ne sont pas encore parties\n",
    "    best_seuil[\"Profit_total_du_mois_actuel\"] = Profit_total_du_mois_actuel\n",
    "\n",
    "    for i in tqdm(table_choix_seuil['SEUIL']) :\n",
    "        seuil = i\n",
    "        y_predict_seuil = (y_proba[:, 1]>=seuil)\n",
    "        Confusion_matrix = confusion_matrix(y_df, y_predict_seuil)\n",
    "        Confusion_matrix = pd.DataFrame(Confusion_matrix)\n",
    "\n",
    "        # Calcul :\n",
    "        nb_client_churner_obs = Confusion_matrix[1][1] + Confusion_matrix[0][1] #Tot_OBS_1 = observation total de tous les churner (True_positive + False_negative)\n",
    "        Profit_total_mois_prochain_sans_model = Profit_total_du_mois_actuel - profit_1client_1mois*nb_client_churner_obs\n",
    "\n",
    "        TP = Confusion_matrix[1][1] #TP = true positive\n",
    "        FN = Confusion_matrix[0][1] #FP = false negative\n",
    "        Tot_PRED_1 = Confusion_matrix[1][1] + Confusion_matrix[1][0]  #Tot_PRED_1 = observation total de tous les churner prédit par le modèle (true_pos + false_pos)\n",
    "        Profit_total_mois_prochain_avec_model = Profit_total_du_mois_actuel - ((Tot_PRED_1*remise_pour_1churner_predit_1mois) + (FN*profit_1client_1mois) - (TP*profit_1client_1mois))\n",
    "\n",
    "        Gain_sur_perte_de_profit_grace_model_1mois = Profit_total_mois_prochain_avec_model - Profit_total_mois_prochain_sans_model  \n",
    "        if Gain_sur_perte_de_profit_grace_model_1mois > best_seuil[\"Gain_de_profit_grace_model_1mois\"] :\n",
    "            best_seuil[\"seuil\"] = seuil\n",
    "            best_seuil[\"recall\"] = str(recall_score(y_df, y_predict_seuil))\n",
    "            best_seuil[\"precision\"] = str(precision_score(y_df, y_predict_seuil))\n",
    "            best_seuil[\"Profit_total_mois_prochain_sans_model_1mois\"] = Profit_total_mois_prochain_sans_model\n",
    "            best_seuil[\"Profit_total_mois_prochain_avec_model_1mois\"] = Profit_total_mois_prochain_avec_model\n",
    "            best_seuil[\"Gain_sur_perte_de_profit_grace_model_1mois\"] = Gain_sur_perte_de_profit_grace_model_1mois\n",
    "\n",
    "    return best_seuil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On sait que la recharge moyenne est de 12,5 par mois\n",
    "# Pour 1.2 euros/recharge, on estime à une dépense moyenne de 15euros par mois\n",
    "# Profit = 0.4*15 = 6\n",
    "best_seuil = choose_best_seuil(x_df=x_val, y_df=y_val, prix_1recharge=1.2, pourcentage_profit=0.4, remise_pour_1churner_predit_1mois=4)\n",
    "best_seuil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-yLhawjW8ZCr",
    "outputId": "36f6ab7f-e8a0-4ea2-b624-b6ecbf3ef378"
   },
   "outputs": [],
   "source": [
    "seuil = best_seuil[\"seuil\"]\n",
    "\n",
    "y_val_predict_seuil = (y_val_proba[:, 1]>=seuil)\n",
    "\n",
    "print(\"Metrique pour le jeu de données val avec le meilleur seuil : \")\n",
    "\n",
    "print(\"\\n Recall : \" + str(recall_score(y_val, y_val_predict_seuil)))\n",
    "print(\"\\n Précision : \" + str(precision_score(y_val, y_val_predict_seuil)))\n",
    "\n",
    "Confusion_matrix_val = confusion_matrix(y_val, y_val_predict_seuil)\n",
    "print(pd.DataFrame(Confusion_matrix_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DOYTA8o63L-W"
   },
   "source": [
    "### Lift curve :\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 489
    },
    "id": "Ml1GVcnm3L-W",
    "outputId": "95e77d2f-db03-4421-f971-fd5cf774fbe3"
   },
   "outputs": [],
   "source": [
    "#courbe lift\n",
    "#method 1 :\n",
    "import scikitplot as skplt\n",
    "\n",
    "plt.figure(figsize=(7,7))\n",
    "y_predict_proba = best_model_xgboost.predict_proba(x_val)\n",
    "skplt.metrics.plot_lift_curve(y_val,y_predict_proba)\n",
    "plt.show()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 235
    },
    "id": "cemyOcUD3L-X",
    "outputId": "9725d091-1347-4a83-eb03-24388ca2bedc"
   },
   "outputs": [],
   "source": [
    "res_modele=pd.DataFrame()\n",
    "res_modele[\"Target\"]=y_val\n",
    "res_modele[\"Proba_target\"]= best_model_xgboost.predict_proba(x_val)[:,1]\n",
    "\n",
    "res_modele.sort_values(by =[\"Proba_target\"], inplace = True,ascending=False)\n",
    "\n",
    "res_modele['QuantileRank']= pd.qcut(res_modele[\"Proba_target\"], q = 10, labels = False)\n",
    "res_modele.head(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZIiH780L3L-X",
    "outputId": "b718f9a4-0b22-4e82-9567-4f128ff1009b"
   },
   "outputs": [],
   "source": [
    "agg_tmp=pd.DataFrame(res_modele.groupby('QuantileRank')['Target'].agg(['sum','count']))\n",
    "agg_tmp.sort_values(by =[\"QuantileRank\"], inplace = True,ascending=False)\n",
    "print(agg_tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0YzPyJUJ3L-Y",
    "outputId": "8d8378af-0d3e-4962-988b-d8df753d8a8b"
   },
   "outputs": [],
   "source": [
    "agg_tmp[\"Precision\"] = agg_tmp[\"sum\"]/agg_tmp[\"count\"]\n",
    "agg_tmp[\"Proba_alatoire\"]= y_val.mean()\n",
    "agg_tmp[\"lift\"]=agg_tmp[\"Precision\"]/agg_tmp[\"Proba_alatoire\"]\n",
    "agg_tmp[\"Part population cible\"]=agg_tmp[\"sum\"]/y_val.sum()\n",
    "agg_tmp[\"Part population\"]=agg_tmp[\"count\"]/y_val.count()\n",
    "print(agg_tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "dw-TyuL03L-Y",
    "outputId": "97fd36f5-9d69-4934-cfb7-0518668eb0fb"
   },
   "outputs": [],
   "source": [
    "#methode 2 :\n",
    "import kds\n",
    "kds.metrics.report(y_val, best_model_xgboost.predict_proba(x_val)[:,1])"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "id": "AM_4LYIj8ZCs"
   },
   "source": [
    "*sélection/modèle aléatoire : on se base sur la moyenne, si il y a 30% de churn dans l'échantillon, alors le modèle aléatoire va prédire une proba (ou score) de 0.3 (ou 30%) d'être un churn pour tous les individus.\n",
    "\n",
    "Lift curve :\n",
    "(abscisse = x fois plus de churn detecter par le modèle lightgbm par rapport au modèle aléatoire\n",
    "ordonnée = x% individus de l'échantillon les plus probable d'être un churn selon le modèle Lightgbm, et x% de l'échantillon sélectionnée de manière aléa)\n",
    "\n",
    "- Si nous prenons les 20 premiers quantiles(ou les 20%) de tout l'échantillon(test ou train) qui ont la plus grand proba d'être un churn (càd d'être égal à 1) selon le modèle, alors on arrivera à capter environs 2.35 fois plus de vrai churn (dans l'échantillon des 20 premiers quantiles) que si on sélectionnait 20% de l'échantillon(train/test) de manière aléatoire.\n",
    "- Interssant si on cherche à évaluer la performance de détection de churn.\n",
    "\n",
    "- trait noir : courbe lift entre le modèle aléatoire et le modèle aléatoire (perf alea/perf alea)\n",
    "Si par exemple on a 30% de churn dans l'échantillon, alors qlq soit l'échantillon (10%, 30%, 60%...), le modèle aléatoire va faire une perf de 30% (ou va réussir à choper 30% de churn parmi ses x% de sélection aléatoire).\n",
    "- trait bleu : courbe de lift entre le modèle LightGBM et le modèle aléatoire (perf Lightgbm/perf alea)\n",
    "\n",
    "- exemple : si on prend les 20% les plus probables d'être un churn (selon le modèle), alors on considère que ces 20% sont tous des churn.\n",
    " si on prend les 100% les plus probables d'être un churn (selon le modèle), alors on considère que ces 100% sont tous des churn. ainsi si dans l'échantillon (des 100%), on considère que ce sont tous des churn et qu'il y a en réalité que 30% de vrai churn, alors le modèle fera que 30% de perf, tout comme le modèle aléatoire). d'où courbe lift = 1 quand on est à 100%.\n",
    "\n",
    "(En fait lorsque le decile est à 100, cela veut dire qu'on prend les 100 les plus proba d'être un churn (en gros on que 100% de l'échantillon sont des churn ou égale à 1), ainsi il fait autant de perf que le modèle aléatoire, car (par ex si on a 30% de vrai churn) le modèle qui prédit que tout l'échantillon sont des churn, alors on aura 30% de bonne réponse, ce qui est autant que le modèle aléatoire.)\n",
    "\n",
    "\n",
    "Gain plot :\n",
    "(abscisse = pourcentage de churner trouver (% par rapport au nb de churner total)\n",
    "ordonnée = x% individus de l'échantillon les plus probable d'être un churn selon le modèle Lightgbm (trait bleu), et x% de l'échantillon sélectionnée de manière aléa (trait noir))\n",
    "\n",
    "- Ici le but est de détecter le plus de churn possible sans forcément gaspiller de l'argent au niv de démarche de fidélsation des clients.\n",
    "Ici on peut voir que si on prend les 80% individus qui ont la plus grande proba d'être un churn (ou égale à 1) selon le modèle, alors on peut voir que tous les vrais churn ont été déctectés (ici le recall est au max).\n",
    "Cela veut donc dire que pour éviter de gaspiller de l'argent au niv de démarche de fidélsation des clients, ont pourrait seulement contacter 80% des clients qui ont la plus grande proba d'être un churner au lieu de tout.\n",
    "- Cela peut être intéressant à détecter tous les churns sans gaspiller de l'argent au niv de démarche de fidélsation des clients.\n",
    "\n",
    "\n",
    "KS stat plot :\n",
    "(abscisse = pourcentage de churner trouver (% par rapport au nb de churner total) (trait bleu),  pourcentage de non-churner trouver (% par rapport au nb de churner total) (trait orange)\n",
    "ordonnée = x% individus de l'échantillon les plus probable d'être un churn selon le modèle Lightgbm (trait bleu et orange))\n",
    "\n",
    "- responder = nb de 1 (churner) trouvés\n",
    "- non-responder = nb de non-1 (càd 0) trouvés\n",
    "- Ici le but est de détecter à cb de pourcent (càd cb de x premiers pourcent) on a le plus grand ratio entre détecter le plus de churner (de 1) et le moins de non-churner (de non-1) possible.\n",
    "Dans notre cas, c'est 50%, càd que si on prend les 50 premiers quantiles qui ont la plus grande proba d'être un churn selon le modèle, alors ça sera là où on aura le plus grand ratio.\n",
    "- Cela peut être intéressant si on cherche à optimiser le ratio gain/perte (càd fidéliser le max de churner sans perdre trop d'argent en fidélisant des non-churner)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learning curve :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add tool box\n",
    "from sklearn.model_selection import learning_curve\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "N, train_score, val_score = learning_curve(best_model_xgboost, x_train, y_train, train_sizes= np.linspace(0.1,1,10) ,cv=10, scoring=\"f1\") #or f1_weighted\n",
    "\n",
    "plt.plot(N, train_score.mean(axis=1), label='train')\n",
    "plt.plot(N, val_score.mean(axis=1), label='validation')\n",
    "plt.xlabel('train_sizes')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N, train_score, val_score = learning_curve(best_model_xgboost, x_train, y_train, train_sizes= np.linspace(0.1,1,10) ,cv=10, scoring=\"f1\")\n",
    "\n",
    "#plt.plot(N, train_score.mean(axis=1), label='train')\n",
    "plt.plot(N, val_score.mean(axis=1), label='validation')\n",
    "plt.xlabel('train_sizes')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "https://vitalflux.com/learning-curves-explained-python-sklearn-example/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zbHntKOg3L-Z"
   },
   "source": [
    "<a class=\"anchor\" id=\"section_5_3\"></a>\n",
    "<div style=\"border: 1px solid RGB(119, 150, 203);\" >\n",
    "    <h3 style=\"margin: auto; padding: 20px; color: RGB(119, 150, 203); \">Features impact analysis</h3>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hHhN5RC13L-Z"
   },
   "source": [
    "### Identification des variables les plus importantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 419
    },
    "id": "tqu3Pztv3L-Z",
    "outputId": "7e4206bb-70cb-4b60-c4be-fbf8b69e2935"
   },
   "outputs": [],
   "source": [
    "(pd.DataFrame({'Features': best_model_xgboost.feature_names_in_,\n",
    "              'Features importance (in %)': (best_model_xgboost.feature_importances_)*100})).sort_values(by='Features importance (in %)', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SHAP value des features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "t-x_NbzB3L-a",
    "outputId": "2868f318-47b8-4109-aa9a-a4f31d09874f"
   },
   "outputs": [],
   "source": [
    "#General :\n",
    "# compute the SHAP values for the linear model\n",
    "explainer = shap.Explainer(best_model_xgboost.predict, x_train)\n",
    "shap_values = explainer(x_train[:5000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 374
    },
    "id": "RnADtEF33L-a",
    "outputId": "e4deffe2-f6d0-4617-d36f-a464baf486dd"
   },
   "outputs": [],
   "source": [
    "shap.plots.beeswarm(shap_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.summary_plot(shap_values, plot_type='violin', max_display=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 418
    },
    "id": "jZrYyfil3L-b",
    "outputId": "b6f39406-aef6-418d-a778-b485c3e572b6"
   },
   "outputs": [],
   "source": [
    "shap.plots.bar(shap_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "duLvS2L_3L-b"
   },
   "source": [
    "<a class=\"anchor\" id=\"section_5_4\"></a>\n",
    "<div style=\"border: 1px solid RGB(119, 150, 203);\" >\n",
    "    <h3 style=\"margin: auto; padding: 20px; color: RGB(119, 150, 203); \">Sérialisation du modèle et déploiement en situation réelle</h3>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vOCaVKtz3L-c",
    "outputId": "60e7980f-c06e-4694-b427-56eff37415e1"
   },
   "outputs": [],
   "source": [
    "#the best model is model(hyper-param)\n",
    "\n",
    "joblib.dump(value = best_model_xgboost, filename = '/home/jupyter/model/scoring_model.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8FHdAbqv3L-c"
   },
   "outputs": [],
   "source": [
    "#load model :\n",
    "scoring_model = joblib.load(filename = '/home/jupyter/model/scoring_model.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7w6NY0HK3L-c"
   },
   "outputs": [],
   "source": [
    "#predict churn : (to review)\n",
    "def predict_churn(model, feature_dict):\n",
    "\n",
    "    df_for_pred = pd.DataFrame(feature_dict)\n",
    "\n",
    "    # Feature engineering :\n",
    "    df_for_pred[\"FLAG_RECHARGE_M1\"] = df_for_pred[\"RECENCY_OF_LAST_RECHARGE\"].apply(lambda x : 1 if 0 <= x <= 31 else 0)\n",
    "    df_for_pred[\"FLAG_RECHARGE_M2\"] = df_for_pred[\"RECENCY_OF_LAST_RECHARGE\"].apply(lambda x : 1 if 32 <= x <= 62 else 0)\n",
    "    df_for_pred[\"FLAG_RECHARGE_M3\"] = df_for_pred[\"RECENCY_OF_LAST_RECHARGE\"].apply(lambda x : 1 if 63 <= x <= 92 else 0)\n",
    "    df_for_pred[\"FLAG_RECHARGE_PLUS_M3\"] = df_for_pred[\"RECENCY_OF_LAST_RECHARGE\"].apply(lambda x : 1 if x >= 93 else 0)\n",
    "\n",
    "    for index, row in df_for_pred.iterrows():\n",
    "        if row[\"BALANCE_M1\"] > row[\"BALANCE_M2\"] and row[\"BALANCE_M2\"] > row[\"BALANCE_M3\"] :\n",
    "            df_for_pred.at[index, \"AVERAGE_MULTIPLE_RECHARGE_M1_M2_M3\"] = 1\n",
    "\n",
    "        else :\n",
    "            df_for_pred.at[index, \"AVERAGE_MULTIPLE_RECHARGE_M1_M2_M3\"] = 0\n",
    "\n",
    "    for index, row in df_for_pred.iterrows() :\n",
    "        if row[\"INC_DURATION_MINS_M1\"] + row[\"INC_PROP_SMS_CALLS_M1\"] == 0 :\n",
    "            df_for_pred.at[index, \"FLAG_IN_M1\"] = 0\n",
    "        else :\n",
    "            df_for_pred.at[index, \"FLAG_IN_M1\"] = 1\n",
    "        if row[\"INC_DURATION_MINS_M2\"] + row[\"INC_PROP_SMS_CALLS_M2\"] == 0 :\n",
    "            df_for_pred.at[index, \"FLAG_IN_M2\"] = 0\n",
    "        else :\n",
    "            df_for_pred.at[index, \"FLAG_IN_M2\"] = 1\n",
    "        if row[\"INC_DURATION_MINS_M3\"] + row[\"INC_PROP_SMS_CALLS_M3\"] == 0 :\n",
    "            df_for_pred.at[index, \"FLAG_IN_M3\"] = 0\n",
    "        else :\n",
    "            df_for_pred.at[index, \"FLAG_IN_M3\"] = 1\n",
    "\n",
    "    for index, row in df_for_pred.iterrows() :\n",
    "        if row[\"OUT_DURATION_MINS_M1\"] + row[\"OUT_SMS_NO_M1\"] + row[\"OUT_INT_DURATION_MINS_M1\"] + row[\"OUT_888_DURATION_MINS_M1\"] + row[\"OUT_VMACC_NO_CALLS_M1\"] == 0 :\n",
    "            df_for_pred.at[index, \"FLAG_OUT_M1\"] = 0\n",
    "        else :\n",
    "            df_for_pred.at[index, \"FLAG_OUT_M1\"] = 1\n",
    "        if row[\"OUT_DURATION_MINS_M2\"] + row[\"OUT_SMS_NO_M2\"] + row[\"OUT_INT_DURATION_MINS_M2\"] + row[\"OUT_888_DURATION_MINS_M2\"] + row[\"OUT_VMACC_NO_CALLS_M2\"] == 0 :\n",
    "            df_for_pred.at[index, \"FLAG_OUT_M2\"] = 0\n",
    "        else :\n",
    "            df_for_pred.at[index, \"FLAG_OUT_M2\"] = 1\n",
    "        if row[\"OUT_DURATION_MINS_M3\"] + row[\"OUT_SMS_NO_M3\"] + row[\"OUT_INT_DURATION_MINS_M3\"] + row[\"OUT_888_DURATION_MINS_M3\"] + row[\"OUT_VMACC_NO_CALLS_M3\"] == 0 :\n",
    "            df_for_pred.at[index, \"FLAG_OUT_M3\"] = 0\n",
    "        else :\n",
    "            df_for_pred.at[index, \"FLAG_OUT_M3\"] = 1\n",
    "\n",
    "    for index, row in df_for_pred.iterrows() :\n",
    "        if row[\"CONTRACT_TENURE_DAYS\"] > 730 :\n",
    "            df_for_pred.at[index, \"OLD_CONTRACT\"] = 1\n",
    "        else :\n",
    "            df_for_pred.at[index,\"OLD_CONTRACT\"] = 0\n",
    "\n",
    "    # 1st feature selection :\n",
    "    df_for_pred.drop(list_col_to_drop, axis=1, inplace=True)\n",
    "\n",
    "    # Encode only cat features :\n",
    "    df_for_pred = a.pre_processing(df=df_for_pred, train=False, categorical_var_OHE= list_cat_col_OHE,\n",
    "                                   categorical_var_OrdinalEncoding={}, categorical_var_TE=list_cat_col_TE, target=y_train,\n",
    "                                   continious_var=[], encoding_type_cont=StandardScaler())\n",
    "\n",
    "    # 2nd feature selection RFE :\n",
    "    #df_for_pred = df_for_pred[list(selector.get_feature_names_out())]\n",
    "    \n",
    "    # Reorder the feature for xgboost :\n",
    "    df_for_pred = df_for_pred[scoring_model.get_booster().feature_names]\n",
    "\n",
    "    return {\"Churn\" : (model.predict(df_for_pred))[0] ,\n",
    "            \"Proba 0 \": [round(elem, 2) for elem in list(model.predict_proba(df_for_pred)[0])][0],\n",
    "            \"Proba 1 \": [round(elem, 2) for elem in list(model.predict_proba(df_for_pred)[0])][1]\n",
    "           } , df_for_pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zCsszVPn3L-d",
    "outputId": "0c222e98-9e2c-4c34-bef9-c82f7529e179"
   },
   "outputs": [],
   "source": [
    "#example of prediction on random observation :\n",
    "feature_dict = {'CUSTOMER_AGE': [43],'CONTRACT_TENURE_DAYS': [1168.0], 'AVERAGE_CHARGE_6M': [25.0], 'FAILED_RECHARGE_6M': [0],\n",
    "             'AVERAGE_RECHARGE_TIME_6M': [200], 'BALANCE_M3': [30.24], 'BALANCE_M2': [77.64], 'BALANCE_M1': [98.44],\n",
    "             'FIRST_RECHARGE_VALUE': [100], 'LAST_RECHARGE_VALUE': [50], 'TIME_TO_GRACE': [-20], 'TIME_TO_AFTERGRACE': [-30],\n",
    "             'RECENCY_OF_LAST_RECHARGE': [10], 'TOTAL_RECHARGE_6M': [200],'NO_OF_RECHARGES_6M': [3], 'ZERO_BALANCE_IND_M2': [0],\n",
    "             'ZERO_BALANCE_IND_M1': [0], 'PASS_GRACE_IND_M3': [1], 'PASS_GRACE_IND_M2': [1], 'PASS_GRACE_IND_M1': [1],\n",
    "             'PASS_AFTERGRACE_IND_M3': [0], 'PASS_AFTERGRACE_IND_M2': [0], 'DATA_FLAG': [1], 'INT_FLAG': [0], 'NUM_HANDSET_USED_6M': [2],\n",
    "             'INC_DURATION_MINS_M3': [37], 'INC_PROP_SMS_CALLS_M3': [0], 'INC_PROP_OPE1__MIN_M1': [0.52], 'INC_PROP_OPE2_MIN_M1': [0.32],\n",
    "             'INC_PROP_OPE2_MIN_M2': [0.4],'INC_PROP_FIXED_MIN_M1': [0.16],'INC_PROP_FIXED_MIN_M3': [0.46],'OUT_DURATION_MINS_M2': [22],\n",
    "             'OUT_DURATION_MINS_M3': [12],'OUT_SMS_NO_M1': [6],'OUT_SMS_NO_M2': [3],'OUT_SMS_NO_M3': [3],'OUT_INT_DURATION_MINS_M1': [0],\n",
    "             'OUT_INT_DURATION_MINS_M2': [0],'OUT_888_DURATION_MINS_M1': [0],'OUT_888_DURATION_MINS_M2': [0],'OUT_888_DURATION_MINS_M3': [0],\n",
    "             'OUT_VMACC_NO_CALLS_M2': [0],'OUT_VMACC_NO_CALLS_M3': [1],'OUT_PROP_SMS_CALLS_M1': [0.2],'OUT_PROP_SMS_CALLS_M2': [0.19],\n",
    "             'OUT_PROP_SMS_CALLS_M3': [0.25],'OUT_PROP_OPE1__MIN_M1': [0.58],'OUT_PROP_OPE1__MIN_M2': [0],'OUT_PROP_OPE1__MIN_M3': [0],\n",
    "             'OUT_PROP_OPE2_MIN_M1': [0],'OUT_PROP_FIXED_MIN_M1': [0],'OUT_PROP_FIXED_MIN_M2': [0.05],'OUT_PROP_FIXED_MIN_M3': [0],\n",
    "             'INC_OUT_PROP_DUR_MIN_M1': [3.13],'INC_OUT_PROP_DUR_MIN_M2': [1.59],'INC_OUT_PROP_DUR_MIN_M3': [3.08],\n",
    "             'CUSTOMER_GENDER': [\"male\"],'ZERO_BALANCE_IND_M3': [0],'ROAM_FLAG': [0],'INC_DURATION_MINS_M2': [0], 'INC_PROP_SMS_CALLS_M1': [0], 'INC_DURATION_MINS_M1':[0],\n",
    "             'INC_PROP_OPE1__MIN_M3': [0],'INC_PROP_FIXED_MIN_M2': [0],'OUT_INT_DURATION_MINS_M3': [0],'OUT_PROP_OPE2_MIN_M2': [0],'OUT_PROP_OPE2_MIN_M3': [0],\n",
    "             'INC_PROP_SMS_CALLS_M3': [1],  \"OUT_DURATION_MINS_M1\":[1], 'INC_PROP_SMS_CALLS_M2': [0], 'INC_DURATION_MINS_M1':[0], \"marque\": [\"nokia\"],\n",
    "             'PASS_AFTERGRACE_IND_M1' : [0], 'INC_PROP_OPE1__MIN_M2': [0], 'INC_PROP_OPE2_MIN_M3': [0], 'OUT_VMACC_NO_CALLS_M1': [0]}\n",
    "\n",
    "predict_churn(scoring_model, feature_dict)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "svvHRGaL3L-d"
   },
   "source": [
    "### Explication du résultat avec Shapley value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "N5MGvoil3L-e"
   },
   "outputs": [],
   "source": [
    "df_p_h = predict_churn(scoring_model, feature_dict)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "I-ysEzZL3L-e"
   },
   "outputs": [],
   "source": [
    "# compute the SHAP values for the linear model\n",
    "explainer = shap.Explainer(best_model_xgboost.predict, x_train)\n",
    "shap_values = explainer(df_p_h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YKC5FFzK3L-e",
    "outputId": "57ed0d0d-0cf6-49dc-d2be-253a352c4667"
   },
   "outputs": [],
   "source": [
    "#particular\n",
    "\n",
    "#The additive nature of Shapley values\n",
    "# the waterfall_plot shows how we get from shap_values.base_values to model.predict(X)[sample_ind]\n",
    "shap.plots.waterfall(shap_values[0], max_display=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.initjs()\n",
    "shap.plots.force(shap_values[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "environment": {
   "kernel": "python3",
   "name": "tf2-gpu.2-11.m109",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-11:m109"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
